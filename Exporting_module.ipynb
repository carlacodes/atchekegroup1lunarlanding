{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "9EanvrrhobbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1b3f16-45b8-41e8-aac7-0eb34b47d54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 177 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 60.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 47.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 448 kB 6.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install dependencies\n",
        "!sudo apt-get update > /dev/null 2>&1\n",
        "!sudo apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install rarfile --quiet\n",
        "!pip install stable-baselines3[extra] ale-py==0.7.4 --quiet\n",
        "!pip install box2d-py --quiet\n",
        "!pip install gym pyvirtualdisplay --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {},
        "id": "pE3qZJLcobbW"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import io\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import base64\n",
        "import stable_baselines3\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.wrappers import Monitor,RecordVideo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gym.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPoZnSTGFvEp",
        "outputId": "489d7c9e-db70-415c-fc65-d589cf586f51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {},
        "id": "fp1bUnClobbY"
      },
      "outputs": [],
      "source": [
        "# @title Plotting/Video functions\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment\n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else:\n",
        "    print(\"Could not find video\")\n",
        "\n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  # env = RecordVideo(env, './video')\n",
        "  return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {},
        "id": "vJm_qzWkobbg"
      },
      "outputs": [],
      "source": [
        "nn_layers = [64,64] #This is the configuration of your neural network. Currently, we have two layers, each consisting of 64 neurons.\n",
        "                    #If you want three layers with 64 neurons each, set the value to [64,64,64] and so on.\n",
        "\n",
        "learning_rate = 0.001 #This is the step-size with which the gradient descent is carried out.\n",
        "                      #Tip: Use smaller step-sizes for larger networks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the obstacle Env for Fine tuning "
      ],
      "metadata": {
        "id": "zb9VfXeFLkbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.envs.box2d import LunarLander\n",
        "from Box2D.b2 import fixtureDef, circleShape, polygonShape, revoluteJointDef, contactListener, edgeShape\n",
        "import math"
      ],
      "metadata": {
        "id": "NfxblZzztMHP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FPS = 50\n",
        "SCALE = 30.0  # affects how fast-paced the game is, forces should be adjusted as well\n",
        "\n",
        "MAIN_ENGINE_POWER = 13.0\n",
        "SIDE_ENGINE_POWER = 0.6\n",
        "\n",
        "INITIAL_RANDOM = 1000.0  # Set 1500 to make game harder\n",
        "\n",
        "LANDER_POLY = [(-14, +17), (-17, 0), (-17, -10), (+17, -10), (+17, 0), (+14, +17)]\n",
        "LEG_AWAY = 20\n",
        "LEG_DOWN = 18\n",
        "LEG_W, LEG_H = 2, 8\n",
        "LEG_SPRING_TORQUE = 40\n",
        "\n",
        "SIDE_ENGINE_HEIGHT = 14.0\n",
        "SIDE_ENGINE_AWAY = 12.0\n",
        "\n",
        "VIEWPORT_W = 600\n",
        "VIEWPORT_H = 400"
      ],
      "metadata": {
        "id": "E6Ivff2jW7q8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContactDetector(contactListener):\n",
        "    def __init__(self, env):\n",
        "        contactListener.__init__(self)\n",
        "        self.env = env\n",
        "\n",
        "    def BeginContact(self, contact):\n",
        "        if (\n",
        "                self.env.lander == contact.fixtureA.body\n",
        "                or self.env.lander == contact.fixtureB.body\n",
        "        ):\n",
        "            self.env.game_over = True\n",
        "        for i in range(2):\n",
        "            if self.env.legs[i] in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                self.env.legs[i].ground_contact = True\n",
        "\n",
        "    def EndContact(self, contact):\n",
        "        for i in range(2):\n",
        "            if self.env.legs[i] in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                self.env.legs[i].ground_contact = False\n",
        "\n",
        "class Custom_LunarLander_obs(LunarLander):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": FPS}\n",
        "    continuous = False\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        enable_wind: bool = False,\n",
        "        wind_power: float = 15.0,\n",
        "        obs_coords = [10, 10],\n",
        "        enable_obstacle: bool = True\n",
        "    ):\n",
        "        LunarLander.__init__(self)\n",
        "\n",
        "        self.enable_wind = enable_wind\n",
        "\n",
        "        self.obs_coords = obs_coords\n",
        "        self.enable_obstacle = enable_obstacle\n",
        "        self.wind_power = wind_power\n",
        "\n",
        "        self.wind_idx = np.random.randint(-9999, 9999)\n",
        "\n",
        "        # defining the polygon obstacle here:\n",
        "        vertices_poly = [(5, 5), (5, 2), (2, 2), (2, 5)]  # may need to change later\n",
        "        # self.obstacle = self.world.CreateStaticBody(\n",
        "        #\n",
        "        #     # shapes=polygonShape(centroid=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #     #                         self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #     #                    vertices= [(x / SCALE, y / SCALE) for x, y in vertices_poly]),\n",
        "        #     shapes=circleShape(pos=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #                             self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #                        radius=2),\n",
        "        #                         categoryBits=0x1000,\n",
        "        #\n",
        "        # )\n",
        "        self.obstacle = self.world.CreateStaticBody(\n",
        "            position=(self.obs_coords[0], self.obs_coords[1]),\n",
        "            # (self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "            # self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE))\n",
        "            angle=0.0,\n",
        "            fixtures=fixtureDef(\n",
        "                #circleShape(radius=2 / SCALE, pos=(0, 0)),\n",
        "                shape=circleShape(radius=20 / SCALE, \n",
        "                                  pos=(self.obs_coords[0],\n",
        "                                       self.obs_coords[1])),\n",
        "                # density=5.0,\n",
        "                # friction=0.1,\n",
        "                # categoryBits=0x0010,\n",
        "                # # maskBits=0x001,  # collide only with ground\n",
        "                # restitution=0.0,\n",
        "            ),  # 0.99 bouncy\n",
        "        )\n",
        "\n",
        "        self.obstacle.color1 = (0.5, 0.4, 0.9)\n",
        "        self.obstacle.color2 = (1, 1, 1)\n",
        "        # self.obstacle.alpha = 0.8  \n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            -np.inf, np.inf, shape=(8,), dtype=np.float32\n",
        "        )   \n",
        "\n",
        "    def reset(self):\n",
        "        self._destroy()\n",
        "        self.world.contactListener_keepref = ContactDetector(self)\n",
        "        self.world.contactListener = self.world.contactListener_keepref\n",
        "        self.game_over = False\n",
        "        self.prev_shaping = None\n",
        "\n",
        "        W = VIEWPORT_W / SCALE\n",
        "        H = VIEWPORT_H / SCALE\n",
        "\n",
        "        # terrain\n",
        "        CHUNKS = 11\n",
        "        height = self.np_random.uniform(0, H / 2, size=(CHUNKS + 1,))\n",
        "        chunk_x = [W / (CHUNKS - 1) * i for i in range(CHUNKS)]\n",
        "        self.helipad_x1 = chunk_x[CHUNKS // 2 - 1]\n",
        "        self.helipad_x2 = chunk_x[CHUNKS // 2 + 1]\n",
        "        self.helipad_y = H / 4\n",
        "        height[CHUNKS // 2 - 2] = self.helipad_y\n",
        "        height[CHUNKS // 2 - 1] = self.helipad_y\n",
        "        height[CHUNKS // 2 + 0] = self.helipad_y\n",
        "        height[CHUNKS // 2 + 1] = self.helipad_y\n",
        "        height[CHUNKS // 2 + 2] = self.helipad_y\n",
        "        smooth_y = [\n",
        "            0.33 * (height[i - 1] + height[i + 0] + height[i + 1])\n",
        "            for i in range(CHUNKS)\n",
        "        ]\n",
        "\n",
        "        self.moon = self.world.CreateStaticBody(\n",
        "            shapes=edgeShape(vertices=[(0, 0), (W, 0)])\n",
        "        )\n",
        "\n",
        "        # defining the polygon obstacle here----------------------------------\n",
        "        vertices_poly = [(5, 5), (5, 2), (2, 2), (2, 5)]  # may need to change later\n",
        "        # self.obstacle = self.world.CreateStaticBody(\n",
        "        #\n",
        "        #     # shapes=polygonShape(centroid=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #     #                         self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #     #                    vertices= [(x / SCALE, y / SCALE) for x, y in vertices_poly]),\n",
        "        #     shapes=circleShape(pos=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #                             self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #                        radius=2),\n",
        "        #                         categoryBits=0x1000,\n",
        "        #\n",
        "        # )\n",
        "        self.obstacle = self.world.CreateStaticBody(\n",
        "            position=(self.obs_coords[0], self.obs_coords[1]),\n",
        "            # (self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "            # self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE))\n",
        "            angle=0.0,\n",
        "            fixtures=fixtureDef(\n",
        "                #circleShape(radius=2 / SCALE, pos=(0, 0)),\n",
        "                shape=circleShape(radius=20 / SCALE, pos=(self.obs_coords[0],\n",
        "                                       self.obs_coords[1])),\n",
        "                # density=5.0,\n",
        "                # friction=0.1,\n",
        "                # categoryBits=0x0010,\n",
        "                # # maskBits=0x001,  # collide only with ground\n",
        "                # restitution=0.0,\n",
        "            ),  # 0.99 bouncy\n",
        "        )\n",
        "\n",
        "        self.obstacle.color1 = (0.5, 0.4, 0.9)\n",
        "        self.obstacle.color2 = (1, 1, 1)\n",
        "        # self.obstacle.alpha = 0.8\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "        self.sky_polys = []\n",
        "        for i in range(CHUNKS - 1):\n",
        "            p1 = (chunk_x[i], smooth_y[i])\n",
        "            p2 = (chunk_x[i + 1], smooth_y[i + 1])\n",
        "            self.moon.CreateEdgeFixture(vertices=[p1, p2], density=0, friction=0.1)\n",
        "            self.sky_polys.append([p1, p2, (p2[0], H), (p1[0], H)])\n",
        "\n",
        "        self.moon.color1 = (0.0, 0.0, 0.0)\n",
        "        self.moon.color2 = (0.0, 0.0, 0.0)\n",
        "\n",
        "        initial_y = VIEWPORT_H / SCALE\n",
        "        self.lander = self.world.CreateDynamicBody(\n",
        "            position=(VIEWPORT_W / SCALE / 2, initial_y),\n",
        "            angle=0.0,\n",
        "            fixtures=fixtureDef(\n",
        "                shape=polygonShape(\n",
        "                    vertices=[(x / SCALE, y / SCALE) for x, y in LANDER_POLY]\n",
        "                ),\n",
        "                density=5.0,\n",
        "                friction=0.1,\n",
        "                categoryBits=0x0010,\n",
        "                maskBits=0x001,  # collide only with ground\n",
        "                restitution=0.0,\n",
        "            ),  # 0.99 bouncy\n",
        "        )\n",
        "        self.lander.color1 = (0.5, 0.4, 0.9)\n",
        "        self.lander.color2 = (0.3, 0.3, 0.5)\n",
        "        self.lander.ApplyForceToCenter(\n",
        "            (\n",
        "                self.np_random.uniform(-INITIAL_RANDOM, INITIAL_RANDOM),\n",
        "                self.np_random.uniform(-INITIAL_RANDOM, INITIAL_RANDOM),\n",
        "            ),\n",
        "            True,\n",
        "        )\n",
        "\n",
        "        self.legs = []\n",
        "        for i in [-1, +1]:\n",
        "            leg = self.world.CreateDynamicBody(\n",
        "                position=(VIEWPORT_W / SCALE / 2 - i * LEG_AWAY / SCALE, initial_y),\n",
        "                angle=(i * 0.05),\n",
        "                fixtures=fixtureDef(\n",
        "                    shape=polygonShape(box=(LEG_W / SCALE, LEG_H / SCALE)),\n",
        "                    density=1.0,\n",
        "                    restitution=0.0,\n",
        "                    categoryBits=0x0020,\n",
        "                    maskBits=0x001,\n",
        "                ),\n",
        "            )\n",
        "            leg.ground_contact = False\n",
        "            leg.color1 = (0.5, 0.4, 0.9)\n",
        "            leg.color2 = (0.3, 0.3, 0.5)\n",
        "            rjd = revoluteJointDef(\n",
        "                bodyA=self.lander,\n",
        "                bodyB=leg,\n",
        "                localAnchorA=(0, 0),\n",
        "                localAnchorB=(i * LEG_AWAY / SCALE, LEG_DOWN / SCALE),\n",
        "                enableMotor=True,\n",
        "                enableLimit=True,\n",
        "                maxMotorTorque=LEG_SPRING_TORQUE,\n",
        "                motorSpeed=+0.3 * i,  # low enough not to jump back into the sky\n",
        "            )\n",
        "            if i == -1:\n",
        "                rjd.lowerAngle = (\n",
        "                        +0.9 - 0.5\n",
        "                )  # The most esoteric numbers here, angled legs have freedom to travel within\n",
        "                rjd.upperAngle = +0.9\n",
        "            else:\n",
        "                rjd.lowerAngle = -0.9\n",
        "                rjd.upperAngle = -0.9 + 0.5\n",
        "            leg.joint = self.world.CreateJoint(rjd)\n",
        "            self.legs.append(leg)\n",
        "\n",
        "        self.drawlist = [self.lander] + self.legs\n",
        "        \n",
        "\n",
        "        return self.step(np.array([0, 0]) if self.continuous else 0)[0]\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.continuous:\n",
        "            action = np.clip(action, -1, +1).astype(np.float32)\n",
        "        else:\n",
        "            assert self.action_space.contains(action), \"%r (%s) invalid \" % (\n",
        "                action,\n",
        "                type(action),\n",
        "            )\n",
        "\n",
        "        # Engines\n",
        "        tip = (math.sin(self.lander.angle), math.cos(self.lander.angle))\n",
        "        side = (-tip[1], tip[0])\n",
        "        dispersion = [self.np_random.uniform(-1.0, +1.0) / SCALE for _ in range(2)]\n",
        "\n",
        "        m_power = 0.0\n",
        "        if (self.continuous and action[0] > 0.0) or (\n",
        "            not self.continuous and action == 2\n",
        "        ):\n",
        "            # Main engine\n",
        "            if self.continuous:\n",
        "                m_power = (np.clip(action[0], 0.0, 1.0) + 1.0) * 0.5  # 0.5..1.0\n",
        "                assert m_power >= 0.5 and m_power <= 1.0\n",
        "            else:\n",
        "                m_power = 1.0\n",
        "            ox = (\n",
        "                tip[0] * (4 / SCALE + 2 * dispersion[0]) + side[0] * dispersion[1]\n",
        "            )  # 4 is move a bit downwards, +-2 for randomness\n",
        "            oy = -tip[1] * (4 / SCALE + 2 * dispersion[0]) - side[1] * dispersion[1]\n",
        "            impulse_pos = (self.lander.position[0] + ox, self.lander.position[1] + oy)\n",
        "            p = self._create_particle(\n",
        "                3.5,  # 3.5 is here to make particle speed adequate\n",
        "                impulse_pos[0],\n",
        "                impulse_pos[1],\n",
        "                m_power,\n",
        "            )  # particles are just a decoration\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * MAIN_ENGINE_POWER * m_power, oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * MAIN_ENGINE_POWER * m_power, -oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        s_power = 0.0\n",
        "        if (self.continuous and np.abs(action[1]) > 0.5) or (\n",
        "            not self.continuous and action in [1, 3]\n",
        "        ):\n",
        "            # Orientation engines\n",
        "            if self.continuous:\n",
        "                direction = np.sign(action[1])\n",
        "                s_power = np.clip(np.abs(action[1]), 0.5, 1.0)\n",
        "                assert s_power >= 0.5 and s_power <= 1.0\n",
        "            else:\n",
        "                direction = action - 2\n",
        "                s_power = 1.0\n",
        "            ox = tip[0] * dispersion[0] + side[0] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            oy = -tip[1] * dispersion[0] - side[1] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            impulse_pos = (\n",
        "                self.lander.position[0] + ox - tip[0] * 17 / SCALE,\n",
        "                self.lander.position[1] + oy + tip[1] * SIDE_ENGINE_HEIGHT / SCALE,\n",
        "            )\n",
        "            p = self._create_particle(0.7, impulse_pos[0], impulse_pos[1], s_power)\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * SIDE_ENGINE_POWER * s_power, oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * SIDE_ENGINE_POWER * s_power, -oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30)\n",
        "\n",
        "        pos = self.lander.position\n",
        "        # print([pos.x,pos.y])\n",
        "        vel = self.lander.linearVelocity\n",
        "      \n",
        "        state = [\n",
        "            (pos.x - VIEWPORT_W / SCALE / 2) / (VIEWPORT_W / SCALE / 2), # 0: x position\n",
        "            (pos.y - (self.helipad_y + LEG_DOWN / SCALE)) / (VIEWPORT_H / SCALE / 2), # 1: y position\n",
        "            vel.x * (VIEWPORT_W / SCALE / 2) / FPS, # 2\n",
        "            vel.y * (VIEWPORT_H / SCALE / 2) / FPS, # 3\n",
        "            self.lander.angle, # 4\n",
        "            20.0 * self.lander.angularVelocity / FPS, # 5\n",
        "            1.0 if self.legs[0].ground_contact else 0.0, # 6\n",
        "            1.0 if self.legs[1].ground_contact else 0.0, # 7\n",
        "\n",
        "            # (pos.x - self.obs_coords[0] / SCALE) / (VIEWPORT_W / SCALE / 2), # 8: x position\n",
        "            # (pos.y - self.obs_coords[1] / SCALE) / (VIEWPORT_H / SCALE / 2), # 9: y position\n",
        "\n",
        "        ]\n",
        "        assert len(state) == 8\n",
        "\n",
        "        state_8 = (pos.x - self.obs_coords[0] / SCALE) / (VIEWPORT_W / SCALE / 2);\n",
        "        state_9 = (pos.y - self.obs_coords[1] / SCALE) / (VIEWPORT_H / SCALE / 2);\n",
        "\n",
        "        # ----------------------------------------------------------------\n",
        "        # reward\n",
        "        # distance_to_obstacle = np.sqrt((pos.x - (self.obs_coords[0] +\n",
        "        #                                     VIEWPORT_W / SCALE / 2)) ** 2 +\n",
        "        #                         (pos.y - (self.obs_coords[1] +\n",
        "\n",
        "        #                                   (self.helipad_y + LEG_DOWN / SCALE))) ** 2)\n",
        "        distance_to_obstacle = np.sqrt(state_8 * state_8 + state_9 * state_9)\n",
        "\n",
        "        # if (distance_to_obstacle <= (1)):\n",
        "        #     print('dangerously close to obstacle!')\n",
        "\n",
        "        reward = 0\n",
        "        shaping = (\n",
        "            # If the lander moves away from the landing pad, it loses reward\n",
        "            - 125 * np.sqrt(state[0] * state[0] + state[1] * state[1]) # Euclidean distance\n",
        "            - 75 * np.sqrt(state[2] * state[2] + state[3] * state[3])\n",
        "\n",
        "            - 100 * abs(state[4])\n",
        "            # Each leg with ground contact is +10 points.\n",
        "            + 10 * state[6]\n",
        "            + 10 * state[7]\n",
        "            - 75 * (distance_to_obstacle <= ((20 + 10) / SCALE)) # obstacles radius and the polly radius  \n",
        "        )  # And ten points for legs contact, the idea is if you\n",
        "        # lose contact again after landing, you get negative reward\n",
        "        if self.prev_shaping is not None:\n",
        "            reward = shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        # Firing the main engine is -0.3 points each frame. \n",
        "        reward -= (\n",
        "            m_power * 0.30\n",
        "        )  # less fuel spent is better, about -30 for heuristic landing\n",
        "        # Firing the side engine is -0.03 points each frame.\n",
        "        reward -= s_power * 0.03\n",
        "\n",
        "        done = False\n",
        "        if self.game_over or abs(state[0]) >= 1.0 : # crashed?\n",
        "            done = True\n",
        "            reward = -100\n",
        "        if not self.lander.awake and (np.sqrt(state[0] * state[0] + state[1] * state[1]) == 0) and (np.sqrt(state[2] * state[2] + state[3] * state[3])==0): # rest\n",
        "            done = True\n",
        "            reward = +200\n",
        "\n",
        "        return np.array(state, dtype=np.float32), reward, done, {}\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        from gym.envs.classic_control import rendering\n",
        "\n",
        "        if self.viewer is None:\n",
        "            self.viewer = rendering.Viewer(VIEWPORT_W, VIEWPORT_H)\n",
        "            self.viewer.set_bounds(0, VIEWPORT_W / SCALE, 0, VIEWPORT_H / SCALE)\n",
        "\n",
        "        for obj in self.particles:\n",
        "            obj.ttl -= 0.15\n",
        "            obj.color1 = (\n",
        "                max(0.2, 0.2 + obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "            )\n",
        "            obj.color2 = (\n",
        "                max(0.2, 0.2 + obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "            )\n",
        "\n",
        "        self._clean_particles(False)\n",
        "        # print('drawlist')\n",
        "        # print(self.drawlist)\n",
        "        for p in self.sky_polys:\n",
        "            self.viewer.draw_polygon(p, color=(0, 0, 0))\n",
        "        # editing below line to draw obstacle\n",
        "        for obj in self.particles + self.drawlist:\n",
        "            for f in obj.fixtures:\n",
        "                trans = f.body.transform\n",
        "                if type(f.shape) is circleShape:\n",
        "                    t = rendering.Transform(translation=trans * f.shape.pos)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj.color1, filled=True\n",
        "                    ).add_attr(t)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj.color2, filled=False, linewidth=2\n",
        "                    ).add_attr(t)\n",
        "                    # t = rendering.Transform((100, 100))  # Position\n",
        "                    # self.viewer.draw_circle(20).add_attr(t)  # Add transform for position\n",
        "                    # self.viewer.render()\n",
        "                else:\n",
        "                    path = [trans * v for v in f.shape.vertices]\n",
        "                    # print('poly shape in object fixtures')\n",
        "                    # print(f)\n",
        "                    self.viewer.draw_polygon(path, color=obj.color1)\n",
        "                    path.append(path[0])\n",
        "                    self.viewer.draw_polyline(path, color=obj.color2, linewidth=2)\n",
        "\n",
        "        for obj2 in [self.obstacle]:\n",
        "            # print('rendering obstacle')\n",
        "            # print(obj2)\n",
        "            for f in obj2.fixtures:\n",
        "                trans = f.body.transform\n",
        "                if type(f.shape) is circleShape:\n",
        "                    # print('printing circle of radius')\n",
        "                    #t = rendering.Transform(translation=trans * f.shape.pos)\n",
        "                    t = rendering.Transform((self.obs_coords[0], self.obs_coords[1]))\n",
        "                    # print(f.shape.radius)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj2.color1, filled=True\n",
        "                    ).add_attr(t)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj2.color2, filled=False, linewidth=2\n",
        "                    ).add_attr(t)\n",
        "                    # t = rendering.Transform((10, 10))  # Position\n",
        "                    # self.viewer.draw_circle(2).add_attr(t)  # Add transform for position\n",
        "                    # self.viewer.render()\n",
        "                else:\n",
        "                    path = [trans * v for v in f.shape.vertices]\n",
        "                    # print('poly shape in object fixtures')\n",
        "                    # print(f)\n",
        "                    self.viewer.draw_polygon(path, color=obj2.color1)\n",
        "                    path.append(path[0])\n",
        "                    self.viewer.draw_polyline(path, color=obj2.color2, linewidth=2)\n",
        "\n",
        "        for x in [self.helipad_x1, self.helipad_x2]:\n",
        "            flagy1 = self.helipad_y\n",
        "            flagy2 = flagy1 + 50 / SCALE\n",
        "            self.viewer.draw_polyline([(x, flagy1), (x, flagy2)], color=(1, 1, 1))\n",
        "            self.viewer.draw_polygon(\n",
        "                [\n",
        "                    (x, flagy2),\n",
        "                    (x, flagy2 - 10 / SCALE),\n",
        "                    (x + 25 / SCALE, flagy2 - 5 / SCALE),\n",
        "                ],\n",
        "                color=(0.8, 0.8, 0),\n",
        "            )\n",
        "\n",
        "        return self.viewer.render(return_rgb_array=mode == \"rgb_array\")\n",
        "\n",
        "\n",
        "    \n",
        "  # def reset(self):\n",
        "  #     pass  # reward, done, info can't be included\n",
        "\n",
        "  # def render(self, mode='human'):\n",
        "  #     pass\n",
        "\n",
        "  # def close(self):\n",
        "  #     pass"
      ],
      "metadata": {
        "id": "MAwXYRAQhpvg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_env2 = Custom_LunarLander_obs()\n",
        "new_env2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c3504d-1729-4995-f108-aeae02f40e42",
        "id": "dxrSUxAgiRPg"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Custom_LunarLander_obs at 0x7ff8b25a4950>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "check_env(new_env2)"
      ],
      "metadata": {
        "id": "5yacX9tliV_Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for env in gym.envs.registration.registry.env_specs.copy():\n",
        "#     if 'LunarLander-v3' in env:\n",
        "#         print(\"Remove {} from registry\".format(env))\n",
        "#         del gym.envs.registration.registry.env_specs[env]"
      ],
      "metadata": {
        "id": "nNOEgfEolroH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.envs.registration import register\n",
        "# Example for the CartPole environment\n",
        "register(\n",
        "    # unique identifier for the env `name-version`\n",
        "    id=\"LunarLander-v4\",\n",
        "    # path to the class for creating the env\n",
        "    # Note: entry_point also accept a class as input (and not only a string)\n",
        "    entry_point= Custom_LunarLander_obs,\n",
        "    # Max number of steps per episode, using a `TimeLimitWrapper`\n",
        "    max_episode_steps=1500,\n",
        ")"
      ],
      "metadata": {
        "id": "pI_O6IZfi6RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577eacff-a67c-487f-8add-8e9d27718e65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:216: UserWarning: \u001b[33mWARN: Overriding environment LunarLander-v4\u001b[0m\n",
            "  logger.warn(\"Overriding environment {}\".format(id))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting the Baseline Model to Pytorch and Fine tuning the Last Layer Using the Obstacle Environment"
      ],
      "metadata": {
        "id": "-zXPpu7LQpFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "print('run pytorch model')\n",
        "import gym\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from stable_baselines3 import DQN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLbWfW6K8tpF",
        "outputId": "7b1709a7-f4e5-439f-bc34-b5418fb390bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run pytorch model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone  https://github.com/Hasanaldhahi3/atchekegroup1lunarlanding.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4Og3pc49huE",
        "outputId": "d2c1c0b5-6775-4730-c704-522e0a34d59f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'atchekegroup1lunarlanding'...\n",
            "remote: Enumerating objects: 739, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 739 (delta 55), reused 42 (delta 42), pack-reused 678\u001b[K\n",
            "Receiving objects: 100% (739/739), 24.48 MiB | 22.01 MiB/s, done.\n",
            "Resolving deltas: 100% (200/200), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib.util\n",
        "# log_dir_ = dir_prefix + \"DQN_Youtube/\"\n",
        "# os.makedirs(log_dir_, exist_ok=True)\n",
        "spec=importlib.util.spec_from_file_location(\"DeepQNetwork\",\"/content/atchekegroup1lunarlanding/YoutubeCodeRepository/ReinforcementLearning/DeepQLearning/simple_dqn_torch_2020.py\")\n",
        "foo_1 = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(foo_1)\n",
        "\n",
        "spec=importlib.util.spec_from_file_location(\"plotLearning\",\"/content/atchekegroup1lunarlanding/YoutubeCodeRepository/ReinforcementLearning/DeepQLearning/utils.py\")\n",
        "foo_2 = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(foo_2)\n",
        "\n",
        "spec=importlib.util.spec_from_file_location(\"Agent\",\"/content/atchekegroup1lunarlanding/YoutubeCodeRepository/ReinforcementLearning/DeepQLearning/simple_dqn_torch_2020.py\")\n",
        "foo_3 = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(foo_3)\n"
      ],
      "metadata": {
        "id": "CsJZwSVj9U_e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_prefix = \"./files/\"\n",
        "log_dir_obstacle = dir_prefix + \"DQN_fine_tuned_Noisey/\"\n",
        "os.makedirs(log_dir_obstacle, exist_ok=True)"
      ],
      "metadata": {
        "id": "K5MHt4nN0SzO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# from YoutubeCodeRepository.ReinforcementLearning.DeepQLearning import simple_dqn_torch_2020\n",
        "\n",
        "print(f\"Is CUDA supported by this system?{torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "\n",
        "# Storing ID of current CUDA device\n",
        "# cuda_id = torch.cuda.current_device()\n",
        "# print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
        "\n",
        "# print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n",
        "# import gym\n",
        "\n",
        "cuda = torch.device('cuda')  # Default CUDA device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3 import DQN\n",
        "\n",
        "# model_path = \"\".format('dqn_lunar')\n",
        "\n",
        "# model_path = log_dir_obstacle + \"model_stable_avg_reward_300 (3).zip\"\n",
        "model_test = DQN.load(\"/content/baseline_weights.zip\")\n",
        "print('loaded model')\n",
        "# for key, value in model_test.get_parameters().items():\n",
        "#     print(key, value.shape)\n",
        "\n",
        "env = gym.make(\"LunarLander-v4\").unwrapped\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "paramshapes = model_test.get_parameters()\n",
        "\n",
        "\n",
        "def copy_dqn_weights(baselines_model):\n",
        "    torch_dqn = foo_1.DeepQNetwork(lr=0.001, n_actions=4, input_dims=[8], fc1_dims=256, fc2_dims=256)\n",
        "    model_params = baselines_model.get_parameters()\n",
        "    # Get only the policy parameters\n",
        "    model_params = model_params['policy']\n",
        "    policy_keys = [key for key in model_params.keys() if \"pi\" in key or \"c\" in key]\n",
        "    policy_params = [model_params[key] for key in policy_keys]\n",
        "\n",
        "    for (th_key, pytorch_param), key, policy_param in zip(torch_dqn.named_parameters(), policy_keys, policy_params):\n",
        "        param = policy_param.copy()\n",
        "        # Copy parameters from stable baselines model to pytorch model\n",
        "\n",
        "        # Conv layer\n",
        "        if len(param.shape) == 4:\n",
        "            # https://gist.github.com/chirag1992m/4c1f2cb27d7c138a4dc76aeddfe940c2\n",
        "            # Tensorflow 2D Convolutional layer: height * width * input channels * output channels\n",
        "            # PyTorch 2D Convolutional layer: output channels * input channels * height * width\n",
        "            param = np.transpose(param, (3, 2, 0, 1))\n",
        "\n",
        "        # weight of fully connected layer\n",
        "        if len(param.shape) == 2:\n",
        "            param = param.T\n",
        "\n",
        "        # bias\n",
        "        if 'b' in key:\n",
        "            param = param.squeeze()\n",
        "\n",
        "        param = torch.from_numpy(param)\n",
        "        pytorch_param.data.copy_(param.data.clone())\n",
        "\n",
        "    return torch_dqn\n",
        "\n",
        "\n",
        "dqn_torch_v = copy_dqn_weights(model_test)\n",
        "ct = 0\n",
        "\n",
        "for child in dqn_torch_v.children():\n",
        "    ct += 1\n",
        "    if ct < 2:\n",
        "        for param in child.parameters():\n",
        "            print(param)\n",
        "            print(ct)\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "print(dqn_torch_v.parameters())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for param in dqn_torch_v.parameters():\n",
        "  param.requires_grad = False\n",
        "num_ftrs = 64  # 8 states we have for the polly to move \n",
        "num_classes = 4 # number of Actions at final layer \n",
        "# ResNet final fully connected layer\n",
        "dqn_torch_v.fc = nn.Linear(num_ftrs, num_classes)\n",
        "dqn_torch_v.to(device)\n",
        "optimizer = torch.optim.Adam(dqn_torch_v.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# import gym\n",
        "\n",
        "\n",
        "# # from YoutubeCodeRepository.ReinforcementLearning.DeepQLearning.utils import plotLearning\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# def obs_to_torch(obs):\n",
        "#     # TF: NHWC\n",
        "#     # PyTorch: NCHW\n",
        "#     # https://discuss.pytorch.org/t/dimensions-of-an-input-image/19439\n",
        "#     # obs = np.transpose(obs, (0, 3, 1, 2))\n",
        "#     # # Normalize\n",
        "#     # obs = obs / 255.0\n",
        "#     obs = th.tensor(obs).float()\n",
        "#     obs = obs.to(device)\n",
        "#     return obs\n",
        "\n",
        "\n",
        "# env = gym.make('LunarLander-v4')\n",
        "\n",
        "# episode_reward = 0\n",
        "# done = False\n",
        "# obs = env.reset()\n",
        "# print(next(dqn_torch_v.parameters()).device)\n",
        "# while not done:\n",
        "#     action = th.argmax(dqn_torch_v(obs_to_torch(obs))).item()\n",
        "#     # action = env.action_space.sample()\n",
        "#     obs, reward, done, _ = env.step(action)\n",
        "#     episode_reward += reward\n",
        "\n",
        "# print(episode_reward)"
      ],
      "metadata": {
        "id": "47vjrBZP9FAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24db898d-3674-4cda-ff93-629eb884ab7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Is CUDA supported by this system?False\n",
            "CUDA version: 11.3\n",
            "cpu\n",
            "loaded model\n",
            "Parameter containing:\n",
            "tensor([[-0.2699,  0.2215, -0.2805,  ...,  0.0768,  0.2879,  0.3533],\n",
            "        [-0.0257, -0.2925, -0.0951,  ...,  0.1328,  0.1329, -0.3405],\n",
            "        [ 0.3069,  0.2371, -0.0466,  ..., -0.2950,  0.3136, -0.1654],\n",
            "        ...,\n",
            "        [ 0.2993, -0.2371, -0.1341,  ...,  0.1764,  0.0587, -0.2268],\n",
            "        [ 0.1419, -0.3017,  0.3421,  ...,  0.3309,  0.3151, -0.1235],\n",
            "        [-0.2089, -0.1852, -0.3029,  ..., -0.1262, -0.1147,  0.2384]],\n",
            "       requires_grad=True)\n",
            "1\n",
            "Parameter containing:\n",
            "tensor([-0.0336,  0.2579,  0.3049, -0.3168, -0.0405,  0.0551,  0.0542,  0.2759,\n",
            "         0.3215, -0.2255,  0.0892, -0.3376, -0.1296,  0.0549,  0.0086,  0.3483,\n",
            "        -0.3105, -0.0151, -0.1516, -0.0812,  0.2399, -0.0945, -0.0795,  0.1701,\n",
            "         0.0569, -0.1270,  0.1957,  0.0594,  0.0798,  0.3439,  0.2332,  0.2575,\n",
            "        -0.3462,  0.2634, -0.3212, -0.1445,  0.2926,  0.1328, -0.0704,  0.3341,\n",
            "        -0.2070,  0.2270, -0.1216,  0.3309,  0.3299, -0.3321, -0.3431, -0.1876,\n",
            "         0.2460, -0.2405, -0.0594,  0.1098,  0.0619, -0.1331, -0.0226,  0.0106,\n",
            "         0.2693, -0.2799, -0.1559,  0.1557, -0.3094, -0.0167, -0.1749, -0.2252,\n",
            "        -0.2997, -0.0884,  0.2729,  0.1063,  0.2781,  0.0420, -0.1359, -0.1636,\n",
            "        -0.1561, -0.1241, -0.1332,  0.1855, -0.3280,  0.1731,  0.2616,  0.0994,\n",
            "        -0.0322,  0.0901, -0.2865,  0.1353,  0.3408, -0.0473, -0.1434,  0.2903,\n",
            "         0.0677,  0.1557,  0.2872,  0.0385, -0.2873, -0.1876, -0.1646, -0.3522,\n",
            "        -0.1121,  0.0571,  0.0714,  0.2680, -0.0580, -0.2201, -0.2486,  0.2876,\n",
            "         0.0375, -0.0763, -0.0524, -0.1231,  0.2352,  0.2835, -0.1164,  0.3422,\n",
            "        -0.2345, -0.1577, -0.3509, -0.3399,  0.0260,  0.3076,  0.0837, -0.1969,\n",
            "         0.3497,  0.0974,  0.1489,  0.2827, -0.2747, -0.0516,  0.3323,  0.2814,\n",
            "         0.1320,  0.0699,  0.2809, -0.0457,  0.2268, -0.0130, -0.1604, -0.0925,\n",
            "        -0.3000, -0.0935,  0.0340,  0.0236, -0.1917,  0.0240,  0.2989,  0.0586,\n",
            "        -0.1174, -0.1682,  0.3185, -0.2086, -0.0210, -0.0636, -0.3340, -0.0155,\n",
            "         0.0991,  0.2144,  0.0567,  0.2103, -0.2173, -0.0564,  0.0525,  0.3312,\n",
            "         0.0679, -0.2402,  0.2016,  0.3393,  0.3408,  0.0808,  0.3329, -0.1862,\n",
            "        -0.1870, -0.2554,  0.3173, -0.2191,  0.0509, -0.2519, -0.2181, -0.1824,\n",
            "         0.0459,  0.2204,  0.2475,  0.0878,  0.0011,  0.2317,  0.3526, -0.0642,\n",
            "        -0.0062,  0.2188,  0.3320, -0.3254, -0.3214,  0.3010, -0.0947,  0.1782,\n",
            "        -0.3135, -0.0796,  0.2452, -0.1053,  0.2338,  0.1890, -0.1025,  0.3486,\n",
            "         0.0631,  0.0882, -0.0176,  0.1981, -0.3266,  0.2033,  0.0188, -0.3023,\n",
            "         0.2795,  0.3414,  0.1982, -0.3114, -0.0374,  0.3310,  0.2813, -0.3048,\n",
            "         0.0528, -0.1564, -0.1738, -0.0187, -0.1911, -0.2737,  0.2147, -0.2513,\n",
            "         0.2119, -0.0172, -0.1393, -0.1406, -0.0802, -0.1132, -0.0987, -0.0053,\n",
            "        -0.1186,  0.1322, -0.0319,  0.2155, -0.0330, -0.0953, -0.0801,  0.2992,\n",
            "         0.3217, -0.1825, -0.3405,  0.1533,  0.3523, -0.0699,  0.0331, -0.2227,\n",
            "        -0.1190,  0.1804, -0.0838,  0.2980,  0.1437,  0.3370,  0.3465,  0.0366],\n",
            "       requires_grad=True)\n",
            "1\n",
            "<generator object Module.parameters at 0x7ff8b2460f50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "# from simple_dqn_torch_2020 import Agent\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make('LunarLander-v4')\n",
        "agent = foo_3.Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=4, eps_end=0.01,\n",
        "              input_dims=[8], lr=0.001)\n",
        "scores_1, eps_history = [], []\n",
        "n_games = 10\n",
        "\n",
        "for i in range(n_games):\n",
        "    score = 0\n",
        "    done = False\n",
        "    observation = env.reset()\n",
        "    while not done:\n",
        "        action = agent.choose_action(observation)\n",
        "        observation_, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "        agent.store_transition(observation, action, reward, \n",
        "                                observation_, done)\n",
        "        agent.learn()\n",
        "        observation = observation_\n",
        "    scores_1.append(score)\n",
        "    eps_history.append(agent.epsilon)\n",
        "\n",
        "    avg_score = np.mean(scores_1[-100:])\n",
        "\n",
        "    print('episode ', i, 'score %.2f' % score,\n",
        "            'average score %.2f' % avg_score,\n",
        "            'epsilon %.2f' % agent.epsilon)\n",
        "x_1 = [i+1 for i in range(n_games)]\n",
        "filename = 'lunar_lander.png'\n",
        "foo_2.plotLearning(x_1, scores_1, eps_history, filename)\n",
        "    # x_np = np.array(x)[indices.astype(int)]\n",
        "    # performance_metrics(x_np,scores)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "oMihRr6Q0sES",
        "outputId": "1226a718-0e30-48c0-e1a0-8c37dd1daa85"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode  0 score -142.58 average score -142.58 epsilon 0.98\n",
            "episode  1 score -232.42 average score -187.50 epsilon 0.94\n",
            "episode  2 score 1.23 average score -124.59 epsilon 0.91\n",
            "episode  3 score -216.18 average score -147.49 epsilon 0.87\n",
            "episode  4 score -84.65 average score -134.92 epsilon 0.82\n",
            "episode  5 score -114.50 average score -131.52 epsilon 0.78\n",
            "episode  6 score -40.33 average score -118.49 epsilon 0.74\n",
            "episode  7 score -89.33 average score -114.85 epsilon 0.68\n",
            "episode  8 score -256.12 average score -130.54 epsilon 0.59\n",
            "episode  9 score -5.54 average score -118.04 epsilon 0.53\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "# from simple_dqn_torch_2020 import Agent\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make('LunarLander-v4')\n",
        "agent2 = foo_3.Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=4, eps_end=0.01,\n",
        "              input_dims=[8], lr=0.001)\n",
        "scores_2, eps_history = [], []\n",
        "n_games = 10\n",
        "\n",
        "for i in range(n_games):\n",
        "    score = 0\n",
        "    done = False\n",
        "    observation = env.reset()\n",
        "    while not done:\n",
        "        action = agent2.choose_action(observation)\n",
        "        observation_, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "        agent.store_transition(observation, action, reward, \n",
        "                                observation_, done)\n",
        "        agent2.learn()\n",
        "        observation = observation_\n",
        "    scores_2.append(score)\n",
        "    eps_history.append(agent2.epsilon)\n",
        "\n",
        "    avg_score = np.mean(scores_2[-100:])\n",
        "\n",
        "    print('episode ', i, 'score %.2f' % score,\n",
        "            'average score %.2f' % avg_score,\n",
        "            'epsilon %.2f' % agent2.epsilon)\n",
        "x_2 = [i+1 for i in range(n_games)]\n",
        "filename = 'lunar_lander.png'\n",
        "foo_2.plotLearning(x_2, scores_2, eps_history, filename)\n",
        "# x_np = np.array(x)[indices.astype(int)]\n",
        "# performance_metrics(x_np,scores)"
      ],
      "metadata": {
        "id": "tyKRwp_gpRDh",
        "outputId": "49a1228f-0780-4bb1-b878-0bb69b7a21bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode  0 score -73.24 average score -73.24 epsilon 1.00\n",
            "episode  1 score -224.17 average score -148.70 epsilon 1.00\n",
            "episode  2 score -42.19 average score -113.20 epsilon 1.00\n",
            "episode  3 score -111.06 average score -112.66 epsilon 1.00\n",
            "episode  4 score -52.58 average score -100.65 epsilon 1.00\n",
            "episode  5 score 27.69 average score -79.26 epsilon 1.00\n",
            "episode  6 score -190.20 average score -95.11 epsilon 1.00\n",
            "episode  7 score -154.02 average score -102.47 epsilon 1.00\n",
            "episode  8 score -136.44 average score -106.25 epsilon 1.00\n",
            "episode  9 score -8.94 average score -96.52 epsilon 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# peformance matrix\n",
        "\n",
        "model_evaluations()"
      ],
      "metadata": {
        "id": "6YaibuklpShc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(agent.Q_eval)\n",
        "torch.save(agent.Q_eval.state_dict(),  \"./sample_data/DQN_tuned_noisy.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDOVWK2Q1PM3",
        "outputId": "005843c3-efd4-4216-d707-ead4d1cc899f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepQNetwork(\n",
            "  (fc1): Linear(in_features=8, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=4, bias=True)\n",
            "  (loss): MSELoss()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "EZFGdYjWDhDG"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "all_model_rewards = {\n",
        "    \"agent\": {\n",
        "        \"x\": np.array(x_1),\n",
        "        \"y\": np.array(scores_1),\n",
        "    },\n",
        "    \"agent2\": {\n",
        "        \"x\": np.array(x_2),\n",
        "        \"y\": np.array(scores_2),\n",
        "    }\n",
        "}\n",
        "\n",
        "def generate_sample_models(number_of_models):\n",
        "    '''\n",
        "    This is function which generates sample models.\n",
        "    '''\n",
        "    for n in range(number_of_models):\n",
        "        reward_dict = {}\n",
        "        model_version_num = 'DQN' + str(n)\n",
        "        x = np.linspace(1,100,100) ## these are the timesteps\n",
        "        y = random.rand(100)\n",
        "        reward_dict = {'x': x, 'y' : y, 'comment': 'here comes the comment'}\n",
        "        all_model_rewards[model_version_num] = reward_dict\n",
        "\n",
        "# generate_sample_models(all_model_rewards)"
      ],
      "metadata": {
        "id": "pOKgF-LxDy-y"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evs = {}\n",
        "\n",
        "def model_evaluations(all_model_rewards): \n",
        "    \n",
        "    '''\n",
        "    This is a function performing model evaluations. \n",
        "    \n",
        "    Input: a dict in the following format:\n",
        "    {'DQN5': {'x': array([  1.,   2.,   3.,  ....]),\n",
        "             'y': array([0.47025739, 0.5788533 , 0.72454499,...]),\n",
        "             'comment': 'comment for the model'}}\n",
        "             \n",
        "             \n",
        "             \n",
        "    The function performing the following metrics:\n",
        "    \n",
        "    \n",
        "    1. Max reward. \n",
        "    2. Jumpstart: The initial performance of an agent in a target task may be improved by transfer from a source task.\n",
        "    3. Asymptotic Performance: The final learned performance of an agent in the target task may be improved via transfer.\n",
        "    4. Total Reward: The total reward accumulated by an agent (i.e., the area under the learning curve) may be improved if it uses transfer, compared to learning without transfer.\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    max_reward = {}\n",
        "    jumpstart = {}\n",
        "    total_reward = {}\n",
        "    asymptotic_performance = {}\n",
        "    \n",
        "    for m in all_model_rewards.keys():\n",
        "        \n",
        "        max_reward[m] = all_model_rewards[m]['y'].max()\n",
        "        \n",
        "        ####################################\n",
        "        ######### NB! Here you can define on how long section do you want to evaluate jumpstart. \n",
        "        ######### It should start from the beginning of the array. \n",
        "        ####################################\n",
        "        jumpstart[m] =  all_model_rewards[m]['y'][:10].mean() \n",
        "        \n",
        "        total_reward[m] =  all_model_rewards[m]['y'].sum()\n",
        "        \n",
        "        ####################################\n",
        "        ######### NB! Here you can define on how long section do you want to evaluate asymptotic performance. \n",
        "        ######### It end at the end of the session.\n",
        "        ####################################\n",
        "        asymptotic_performance[m] =  all_model_rewards[m]['y'][-10:].sum()\n",
        "\n",
        "        \n",
        "        \n",
        "    ## Add the metrics to the final evaluation metric \n",
        "    \n",
        "    model_evs['max_reward'] = max_reward\n",
        "    model_evs['jumpstart'] = jumpstart\n",
        "    model_evs['total_reward'] = total_reward\n",
        "    model_evs['asymptotic_performance'] = asymptotic_performance\n",
        "\n",
        "    # return model_evs\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "model_evaluations(all_model_rewards)  \n",
        "results = pd.DataFrame(model_evs)\n",
        "results.style.highlight_max(color = 'lightgreen', axis = 0)"
      ],
      "metadata": {
        "id": "ODnN1EwXD1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "dd71972c-feaa-4888-cf34-b826e0f5445b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ff8a511a750>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_9d5d3_row1_col0, #T_9d5d3_row1_col1, #T_9d5d3_row1_col2, #T_9d5d3_row1_col3 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9d5d3_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >max_reward</th>\n",
              "      <th class=\"col_heading level0 col1\" >jumpstart</th>\n",
              "      <th class=\"col_heading level0 col2\" >total_reward</th>\n",
              "      <th class=\"col_heading level0 col3\" >asymptotic_performance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9d5d3_level0_row0\" class=\"row_heading level0 row0\" >agent</th>\n",
              "      <td id=\"T_9d5d3_row0_col0\" class=\"data row0 col0\" >1.230848</td>\n",
              "      <td id=\"T_9d5d3_row0_col1\" class=\"data row0 col1\" >-118.042402</td>\n",
              "      <td id=\"T_9d5d3_row0_col2\" class=\"data row0 col2\" >-1180.424016</td>\n",
              "      <td id=\"T_9d5d3_row0_col3\" class=\"data row0 col3\" >-1180.424016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9d5d3_level0_row1\" class=\"row_heading level0 row1\" >agent2</th>\n",
              "      <td id=\"T_9d5d3_row1_col0\" class=\"data row1 col0\" >27.687015</td>\n",
              "      <td id=\"T_9d5d3_row1_col1\" class=\"data row1 col1\" >-96.515605</td>\n",
              "      <td id=\"T_9d5d3_row1_col2\" class=\"data row1 col2\" >-965.156052</td>\n",
              "      <td id=\"T_9d5d3_row1_col3\" class=\"data row1 col3\" >-965.156052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_ratio(transfer_learner, scratch_model): \n",
        "\n",
        "    ''' Transfer Ratio: The ratio of the total reward accumulated by the transfer learner and the total reward accumulated by the non-transfer learner.'''\n",
        "\n",
        "    transfer_ratio = (transfer_learner['y']/scratch_model['y']).sum()\n",
        "    return (transfer_ratio)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def time_to_threshold(transfer_learner, scratch_model):\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    Time to Threshold: The learning time needed by the agent to achieve a pre-specified perfor- mance level may be reduced via knowledge transfer.\n",
        "\n",
        "\n",
        "    This function returns the first timestep of the transfer_learning model when it reaches the scratch\n",
        "    model's maximum value. The threshold could be changed to \n",
        "        - any fixed number\n",
        "        - ratio of the scratch model's maximum reward\n",
        "        - the average of the final performance (averaged over the last n timesteps) of the scratch model. \n",
        "    '''\n",
        "    \n",
        "    threshold = scratch_model['y'].max()\n",
        "    threshold_index = np.where(transfer_learner['y'] >= threshold)[0][0]\n",
        "    \n",
        "    \n",
        "    return 'Transfer learner\\'s performance reaches the threashold (scratch model\\'s max performance) at timestap {}. Threshold is {}'.format(threshold_index, threshold)\n",
        "    \n",
        "transfer_ratio( all_model_rewards[\"agent2\"], all_model_rewards[\"agent\"])  \n",
        "\n",
        "time_to_threshold(all_model_rewards[\"agent2\"], all_model_rewards[\"agent\"])"
      ],
      "metadata": {
        "id": "OS3lNNLXQc2D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6cb8cf6-42ee-4ed3-9a4d-69f8b029c795"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Transfer learner's performance reaches the threashold (scratch model's max performance) at timestap 5. Threshold is 1.230848498392092\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def jumpstart(y):\n",
        "    return (y[0])\n",
        "\n",
        "\n",
        "def asymptotic_performance(y, rolling_avg=1):\n",
        "    asymptotic_performance = np.mean(y[-rolling_avg:])\n",
        "    return asymptotic_performance\n",
        "\n",
        "\n",
        "def total_reward_fnc(y):\n",
        "    return np.sum(y)\n",
        "\n",
        "\n",
        "def transfer_ratio(y_transfer, y_reference, total_reward):\n",
        "    transfer_ratio = total_reward(y_transfer) / total_reward(y_reference)\n",
        "    return transfer_ratio\n",
        "\n",
        "\n",
        "def time_to_threshold(x, y, threshold=250):\n",
        "    return x[np.argmax(y > threshold)]\n",
        "\n",
        "\n",
        "def max_reward_fnc(y):\n",
        "    return np.max(y), np.argmax(y)\n",
        "\n",
        "\n",
        "def performance_metrics(x, y, rolling_avg=10, threshold=275, plot=True):\n",
        "    '''\n",
        "    TODO: write plots functions\n",
        "    '''\n",
        "\n",
        "    max_reward, idx_training_max = max_reward_fnc(y)\n",
        "    total_reward = total_reward_fnc(y)\n",
        "    n_timesteps = max(x)\n",
        "    reward_per_timestep = total_reward / n_timesteps\n",
        "    asymptote = asymptotic_performance(y, rolling_avg=rolling_avg)\n",
        "    std_asymptote = np.std(y[-rolling_avg:])\n",
        "    asymptote_after_max = asymptotic_performance(y, rolling_avg=n_timesteps - idx_training_max)\n",
        "    std_asymptote_after_max = np.std(y[-(n_timesteps - idx_training_max):])\n",
        "    time_threshold = time_to_threshold(x, y, threshold=threshold)\n",
        "    threshold_80 = 0.80 * threshold\n",
        "    time_threshold_80_of_max = time_to_threshold(x, y, threshold=threshold_80)\n",
        "    print(0.80 * max_reward)\n",
        "\n",
        "    print(f\" Max reward: {max_reward} \\\n",
        "        \\n Time steps to max reward: {idx_training_max}/{n_timesteps} ({idx_training_max * 100 / n_timesteps:.2f}% of training period) \\\n",
        "        \\n Total reward: {total_reward:.2f} \\\n",
        "        \\n Reward per timestep: {reward_per_timestep:.2f} \\\n",
        "        \\n Asymptotic performance (last {rolling_avg} timesteps): {asymptote:.2f} ±{std_asymptote:.2f} ({asymptote * 100 / max_reward:.2f}% of max reward) \\\n",
        "        \\n Asymptotic performance after max: {asymptote_after_max:.2f} ±{std_asymptote_after_max:.2f} ({asymptote_after_max * 100 / max_reward:.2f}% of max reward) \\\n",
        "        \\n Time to threshold(={threshold}): {time_threshold}/{n_timesteps} ({time_threshold * 100 / n_timesteps:.2f}% of training period) \\\n",
        "        \\n Time to threshold(80% of max={threshold_80}): {time_threshold_80_of_max}/{n_timesteps} ({time_threshold_80_of_max * 100 / n_timesteps:.2f}% of training period)\" \\\n",
        "          )\n",
        "\n",
        "    if plot == True:\n",
        "        sns.scatterplot(x=x, y=y, color='green')\n",
        "        plt.title('Reward Over Timesteps 2')\n",
        "        plt.xlabel('Episode Index')\n",
        "        plt.ylabel('Reward')\n",
        "        plt.show()\n",
        "\n",
        "        # sns.barplot(data=[asymptote])\n",
        "        # plt.show()\n",
        "        numpy_data = ([threshold, time_threshold_80_of_max])\n",
        "\n",
        "        plt.bar([0, 1], [time_threshold, time_threshold_80_of_max], color=['green', 'blue'])\n",
        "        plt.xticks([0, 1], labels=['Time to Max Threshold', 'Time to 80% max threshold'])\n",
        "        plt.title('Threshold Time')\n",
        "        plt.ylabel('Episode Number')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "XlZF54uNVHNN"
      },
      "execution_count": 33,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Exporting_module.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}