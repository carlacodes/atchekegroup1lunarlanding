{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlacodes/atchekegroup1lunarlanding/blob/sherry/lunar_lander_group1_atcheke.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rKjkh_KgobbF"
      },
      "source": [
        "# Performance Analysis of DQN Algorithm on the Lunar Lander task\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__ Raghuram Bharadwaj Diddigi, Geraud Nangue Tasse, Yamil Vidal, Sanjukta Krishnagopal, Sara Rajaee\n",
        "\n",
        "__Content editors:__ Spiros Chavlis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "iDR5t137obbP"
      },
      "source": [
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "brZ9ZJQzobbR"
      },
      "source": [
        "---\n",
        "# Objective\n",
        "\n",
        "In this project, the objective is to analyze the performance of the Deep Q-Learning algorithm on an exciting task- Lunar Lander. Before we describe the task, let us focus on two keywords here - analysis and performance. What exactly do we mean by these keywords in the context of Reinforcement Learning (RL)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "wpX-jA7GobbT"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {},
        "id": "9EanvrrhobbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173f350c-b4ae-416e-9054-5d59e0132bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 177 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 56.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 61.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 448 kB 4.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install dependencies\n",
        "!sudo apt-get update > /dev/null 2>&1\n",
        "!sudo apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install rarfile --quiet\n",
        "!pip install stable-baselines3[extra] ale-py==0.7.4 --quiet\n",
        "!pip install box2d-py --quiet\n",
        "!pip install gym pyvirtualdisplay --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {},
        "id": "pE3qZJLcobbW"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import io\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import base64\n",
        "import stable_baselines3\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.wrappers import Monitor,RecordVideo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gym.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPoZnSTGFvEp",
        "outputId": "943d9e6e-8277-4abf-b8be-422b5e09c384"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {},
        "id": "fp1bUnClobbY"
      },
      "outputs": [],
      "source": [
        "# @title Plotting/Video functions\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment\n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else:\n",
        "    print(\"Could not find video\")\n",
        "\n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  # env = RecordVideo(env, './video')\n",
        "  return env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive_path = \"/content/gdrive/My Drive/LunarLanding/\""
      ],
      "metadata": {
        "id": "4otSbkh_QAYF",
        "outputId": "c749b8a5-f58a-4faf-a328-fd5b77f7a045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "psfdqUCmobba"
      },
      "source": [
        "---\n",
        "# Introduction\n",
        "\n",
        "In a standard RL setting, an agent learns optimal behavior from an environment through a feedback mechanism to maximize a given objective. Many algorithms have been proposed in the RL literature that an agent can apply to learn the optimal behavior. One such popular algorithm is the Deep Q-Network (DQN). This algorithm makes use of deep neural networks to compute optimal actions. In this project, your goal is to understand the effect of the number of neural network layers on the algorithm's performance. The performance of the algorithm can be evaluated through two metrics - Speed and Stability. \n",
        "\n",
        "**Speed:** How fast the algorithm reaches the maximum possible reward. \n",
        "\n",
        "**Stability** In some applications (especially when online learning is involved), along with speed, stability of the algorithm, i.e., minimal fluctuations in performance, is equally important. \n",
        "\n",
        "In this project, you should investigate the following question:\n",
        "\n",
        "**What is the impact of number of neural network layers on speed and stability of the algorithm?**\n",
        "\n",
        "You do not have to write the DQN code from scratch. We have provided a basic implementation of the DQN algorithm. You only have to tune the hyperparameters (neural network size, learning rate, etc), observe the performance, and analyze. More details on this are provided below. \n",
        "\n",
        "Now, let us discuss the RL task we have chosen, i.e., Lunar Lander. This task consists of the lander and a landing pad marked by two flags. The episode starts with the lander moving downwards due to gravity. The objective is to land safely using different engines available on the lander with zero speed on the landing pad as quickly and fuel efficient as possible. Reward for moving from the top of the screen and landing on landing pad with zero speed is between 100 to 140 points. Each leg ground contact yields a reward of 10 points. Firing main engine leads to a reward of -0.3 points in each frame. Firing the side engine leads to a reward of -0.03 points in each frame. An additional reward of -100 or +100 points is received if the lander crashes or comes to rest respectively which also leads to end of the episode. \n",
        "\n",
        "The input state of the Lunar Lander consists of following components:\n",
        "\n",
        "  1. Horizontal Position\n",
        "  2. Vertical Position\n",
        "  3. Horizontal Velocity\n",
        "  4. Vertical Velocity\n",
        "  5. Angle\n",
        "  6. Angular Velocity\n",
        "  7. Left Leg Contact\n",
        "  8. Right Leg Contact\n",
        "\n",
        "The actions of the agents are:\n",
        "  1. Do Nothing\n",
        "  2. Fire Main Engine\n",
        "  3. Fire Left Engine\n",
        "  4. Fire Right Engine\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/static/lunar_lander.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning hyperparameters"
      ],
      "metadata": {
        "id": "XgNuDz2mrq0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref: \n",
        "\n",
        "1.   template https://github.com/AI4Finance-Foundation/FinRL/blob/master/tutorials/4-Optimization/FinRL_HyperparameterTuning_using_Optuna_basic.ipynb\n",
        "\n",
        "2.   tutorial (combined with template): https://medium.com/analytics-vidhya/hyperparameter-tuning-using-optuna-for-finrl-8a49506d2741\n",
        "\n",
        "3.  set parameter function: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/utils/hyperparams_opt.py\n",
        "\n",
        "4.   callback function: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/utils/callbacks.py#L10\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6RQ_bAC6KlAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install optuna --quiet"
      ],
      "metadata": {
        "id": "qSg7t4EJx9Pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8ccfde-ca8c-4394-abc1-165f69b1cb16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 308 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 63.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 93.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 96.8 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import sys"
      ],
      "metadata": {
        "id": "CHT0LZ0WyERZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define search space"
      ],
      "metadata": {
        "id": "i_gZFwkKtj5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_dqn_params(trial: optuna.Trial):\n",
        "    \"\"\"\n",
        "    Sampler for DQN hyperparams.\n",
        "    :param trial:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    learning_rate = trial.suggest_discrete_uniform('lr', 0.001, 0.01, 0.005)\n",
        "\n",
        "    # net_arch = trial.suggest_categorical(\"net_arch\", [\"two\", \"three\"]) #, \"two_big\"\n",
        "    # net_arch = {\"two\": [64, 64], \"three\": [64, 64, 64]}[net_arch] #, \"two_big\": [256, 256]\n",
        "\n",
        "    hyperparams = {\n",
        "        \"learning_rate\": learning_rate,#\n",
        "        \"policy_kwargs\": dict(activation_fn=torch.nn.ReLU, net_arch=[64, 64]),\n",
        "        \"batch_size\": 1,  #for simplicity, we are not doing batch update.\n",
        "        \"buffer_size\": 1, #size of experience of replay buffer. Set to 1 as batch update is not done\n",
        "        \"learning_starts\": 1, #learning starts immediately!\n",
        "        \"gamma\": 0.99, #discount facto. range is between 0 and 1.\n",
        "        \"tau\": 1,  #the soft update coefficient for updating the target network\n",
        "        \"target_update_interval\": 1, #update the target network immediately.\n",
        "        \"train_freq\": (1,\"step\"), #train the network at every step.\n",
        "        \"max_grad_norm\": 10, #the maximum value for the gradient clipping\n",
        "        \"exploration_initial_eps\": 1, #initial value of random action probability\n",
        "        \"exploration_fraction\": 0.5, #fraction of entire training period over which the exploration rate is reduced\n",
        "        \"gradient_steps\": 1, #number of gradient steps\n",
        "        \"seed\": 1, #seed for the pseudo random generators\n",
        "        \"verbose\": 0\n",
        "    }\n",
        "    return hyperparams"
      ],
      "metadata": {
        "id": "mWhSf_qjk8T4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define callback"
      ],
      "metadata": {
        "id": "fFyJprz6tp7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoggingCallback:\n",
        "    def __init__(self,threshold,trial_number,patience):\n",
        "      '''\n",
        "      threshold: int tolerance for increase in reward\n",
        "      trial_number: int Prune after minimum number of trials\n",
        "      patience: int patience for the threshold\n",
        "      '''\n",
        "      self.threshold = threshold\n",
        "      self.trial_number  = trial_number\n",
        "      self.patience = patience\n",
        "      self.cb_list = [] #Trials list for which threshold is reached\n",
        "    def __call__(self,study:optuna.study, frozen_trial:optuna.Trial):\n",
        "      #Setting the best value in the current trial\n",
        "      study.set_user_attr(\"previous_best_value\", study.best_value)\n",
        "      \n",
        "      #Checking if the minimum number of trials have pass\n",
        "      if frozen_trial.number >self.trial_number:\n",
        "          previous_best_value = study.user_attrs.get(\"previous_best_value\",None)\n",
        "          #Checking if the previous and current objective values have the same sign\n",
        "          if previous_best_value * study.best_value >=0:\n",
        "              #Checking for the threshold condition\n",
        "              if abs(previous_best_value-study.best_value) < self.threshold: \n",
        "                  self.cb_list.append(frozen_trial.number)\n",
        "                  #If threshold is achieved for the patience amount of time\n",
        "                  if len(self.cb_list)>self.patience:\n",
        "                      print('The study stops now...')\n",
        "                      print('With number',frozen_trial.number ,'and value ',frozen_trial.value)\n",
        "                      print('The previous and current best values are {} and {} respectively'\n",
        "                              .format(previous_best_value, study.best_value))\n",
        "                      study.stop()"
      ],
      "metadata": {
        "id": "Q4FKnTdKttOu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define template objective"
      ],
      "metadata": {
        "id": "B1qV393bpoTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = drive_path #\"models\"\n",
        "\n",
        "def objective(trial:optuna.Trial):\n",
        "\n",
        "  model_log_dir = log_dir+'dqn_{}'.format(trial.number)+'/'\n",
        "  os.makedirs(model_log_dir,exist_ok=True) \n",
        "  # Create environment\n",
        "  env = gym.make('LunarLander-v2')\n",
        "  env = stable_baselines3.common.monitor.Monitor(env, filename= model_log_dir)\n",
        "\n",
        "  #Trial will suggest a set of hyperparamters from the specified range\n",
        "  hyperparameters = sample_dqn_params(trial)\n",
        "  model_dqn = DQN(\"MlpPolicy\", env, **hyperparameters) #Set verbose to 1 to observe training logs. We encourage you to set the verbose to 1.\n",
        "\n",
        "  # define learning steps\n",
        "  trained_dqn = model_dqn.learn(total_timesteps=1000, log_interval=10)#100000 , callback=callback\n",
        "  # save model\n",
        "  trained_dqn.save(model_log_dir +'dqn_{}.pth'.format(trial.number)) \n",
        "\n",
        "  x, y = ts2xy(load_results(model_log_dir), 'timesteps') # timesteps\n",
        "  # clear_output(wait=True)\n",
        "  #For the given hyperparamters, determine reward\n",
        "  reward = sum(y)\n",
        "  return reward\n",
        "\n",
        "#Create a study object and specify the direction as 'maximize'\n",
        "#As you want to maximize reward\n",
        "#Pruner stops not promising iterations\n",
        "#Use a pruner, else you will get error related to divergence of model\n",
        "#You can also use Multivariate samplere\n",
        "#sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "study = optuna.create_study(study_name=\"dqn_study\",direction='maximize',\n",
        "                            sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
        "\n",
        "logging_callback = LoggingCallback(threshold=10, patience=30, trial_number=5)\n",
        "#You can increase the n_trials for a better search space scanning\n",
        "study.optimize(objective, n_trials=2, catch=(ValueError,),callbacks=[logging_callback])"
      ],
      "metadata": {
        "id": "2s-bjWndt_a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42c3614-4a36-4756-e21d-7f08b0ad2d34"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-26 21:38:49,875]\u001b[0m A new study created in memory with name: dqn_study\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:548: UserWarning: The distribution is specified by [0.001, 0.01] and q=0.005, but the range is not divisible by `q`. It will be replaced by [0.001, 0.006].\n",
            "  low=low, old_high=old_high, high=high, step=q\n",
            "\u001b[32m[I 2022-07-26 21:38:54,141]\u001b[0m Trial 0 finished with value: -2644.398608 and parameters: {'lr': 0.001}. Best is trial 0 with value: -2644.398608.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:548: UserWarning: The distribution is specified by [0.001, 0.01] and q=0.005, but the range is not divisible by `q`. It will be replaced by [0.001, 0.006].\n",
            "  low=low, old_high=old_high, high=high, step=q\n",
            "\u001b[32m[I 2022-07-26 21:38:58,410]\u001b[0m Trial 1 finished with value: -2592.8647579999997 and parameters: {'lr': 0.006}. Best is trial 1 with value: -2592.8647579999997.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get the best model"
      ],
      "metadata": {
        "id": "tf91UWqvzR6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the best hyperparamters\n",
        "print('Hyperparameters after tuning',study.best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcDma0wSy02u",
        "outputId": "f344e12a-5643-4ea6-82d8-406ca2d2c7e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters after tuning {'lr': 0.006}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_trial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqou4GOlzWMh",
        "outputId": "04a08056-d494-42a8-d379-18cf740deafc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=1, values=[-2592.8647579999997], datetime_start=datetime.datetime(2022, 7, 26, 21, 38, 54, 143016), datetime_complete=datetime.datetime(2022, 7, 26, 21, 38, 58, 410379), params={'lr': 0.006}, distributions={'lr': DiscreteUniformDistribution(high=0.006, low=0.001, q=0.005)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE, value=None)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build three tasks for transfer learning\n"
      ],
      "metadata": {
        "id": "M5vgItPPhsw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref: https://towardsdatascience.com/beginners-guide-to-custom-environments-in-openai-s-gym-989371673952"
      ],
      "metadata": {
        "id": "yIFSDq7eyXY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### define new env class"
      ],
      "metadata": {
        "id": "c-DTrZhLy0UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.envs.box2d import LunarLander\n",
        "from Box2D.b2 import fixtureDef, circleShape, polygonShape, revoluteJointDef, contactListener, edgeShape\n",
        "import math"
      ],
      "metadata": {
        "id": "dTxYseql3ry3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set parameters"
      ],
      "metadata": {
        "id": "MtUy074Syhdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FPS = 50\n",
        "SCALE = 30.0  # affects how fast-paced the game is, forces should be adjusted as well\n",
        "\n",
        "MAIN_ENGINE_POWER = 13.0\n",
        "SIDE_ENGINE_POWER = 0.6\n",
        "\n",
        "INITIAL_RANDOM = 1000.0  # Set 1500 to make game harder\n",
        "\n",
        "LANDER_POLY = [(-14, +17), (-17, 0), (-17, -10), (+17, -10), (+17, 0), (+14, +17)]\n",
        "LEG_AWAY = 20\n",
        "LEG_DOWN = 18\n",
        "LEG_W, LEG_H = 2, 8\n",
        "LEG_SPRING_TORQUE = 40\n",
        "\n",
        "SIDE_ENGINE_HEIGHT = 14.0\n",
        "SIDE_ENGINE_AWAY = 12.0\n",
        "\n",
        "VIEWPORT_W = 600\n",
        "VIEWPORT_H = 400"
      ],
      "metadata": {
        "id": "E6Ivff2jW7q8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### baselien with new reward"
      ],
      "metadata": {
        "id": "Hk3RJY11A0d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_LunarLander_reward(LunarLander):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": FPS}\n",
        "    continuous = False\n",
        "\n",
        "    def __init__(\n",
        "        self\n",
        "    ):\n",
        "        LunarLander.__init__(self)\n",
        "        \n",
        "    def step(self, action):\n",
        "        if self.continuous:\n",
        "            action = np.clip(action, -1, +1).astype(np.float32)\n",
        "        else:\n",
        "            assert self.action_space.contains(action), \"%r (%s) invalid \" % (\n",
        "                action,\n",
        "                type(action),\n",
        "            )\n",
        "\n",
        "        # Engines\n",
        "        tip = (math.sin(self.lander.angle), math.cos(self.lander.angle))\n",
        "        side = (-tip[1], tip[0])\n",
        "        dispersion = [self.np_random.uniform(-1.0, +1.0) / SCALE for _ in range(2)]\n",
        "\n",
        "        m_power = 0.0\n",
        "        if (self.continuous and action[0] > 0.0) or (\n",
        "            not self.continuous and action == 2\n",
        "        ):\n",
        "            # Main engine\n",
        "            if self.continuous:\n",
        "                m_power = (np.clip(action[0], 0.0, 1.0) + 1.0) * 0.5  # 0.5..1.0\n",
        "                assert m_power >= 0.5 and m_power <= 1.0\n",
        "            else:\n",
        "                m_power = 1.0\n",
        "            ox = (\n",
        "                tip[0] * (4 / SCALE + 2 * dispersion[0]) + side[0] * dispersion[1]\n",
        "            )  # 4 is move a bit downwards, +-2 for randomness\n",
        "            oy = -tip[1] * (4 / SCALE + 2 * dispersion[0]) - side[1] * dispersion[1]\n",
        "            impulse_pos = (self.lander.position[0] + ox, self.lander.position[1] + oy)\n",
        "            p = self._create_particle(\n",
        "                3.5,  # 3.5 is here to make particle speed adequate\n",
        "                impulse_pos[0],\n",
        "                impulse_pos[1],\n",
        "                m_power,\n",
        "            )  # particles are just a decoration\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * MAIN_ENGINE_POWER * m_power, oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * MAIN_ENGINE_POWER * m_power, -oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        s_power = 0.0\n",
        "        if (self.continuous and np.abs(action[1]) > 0.5) or (\n",
        "            not self.continuous and action in [1, 3]\n",
        "        ):\n",
        "            # Orientation engines\n",
        "            if self.continuous:\n",
        "                direction = np.sign(action[1])\n",
        "                s_power = np.clip(np.abs(action[1]), 0.5, 1.0)\n",
        "                assert s_power >= 0.5 and s_power <= 1.0\n",
        "            else:\n",
        "                direction = action - 2\n",
        "                s_power = 1.0\n",
        "            ox = tip[0] * dispersion[0] + side[0] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            oy = -tip[1] * dispersion[0] - side[1] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            impulse_pos = (\n",
        "                self.lander.position[0] + ox - tip[0] * 17 / SCALE,\n",
        "                self.lander.position[1] + oy + tip[1] * SIDE_ENGINE_HEIGHT / SCALE,\n",
        "            )\n",
        "            p = self._create_particle(0.7, impulse_pos[0], impulse_pos[1], s_power)\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * SIDE_ENGINE_POWER * s_power, oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * SIDE_ENGINE_POWER * s_power, -oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30)\n",
        "\n",
        "        pos = self.lander.position\n",
        "        vel = self.lander.linearVelocity\n",
        "        state = [\n",
        "            (pos.x - VIEWPORT_W / SCALE / 2) / (VIEWPORT_W / SCALE / 2), # 0: x position\n",
        "            (pos.y - (self.helipad_y + LEG_DOWN / SCALE)) / (VIEWPORT_H / SCALE / 2), # 1: y position\n",
        "            vel.x * (VIEWPORT_W / SCALE / 2) / FPS, # 2\n",
        "            vel.y * (VIEWPORT_H / SCALE / 2) / FPS, # 3\n",
        "            self.lander.angle, # 4\n",
        "            20.0 * self.lander.angularVelocity / FPS, # 5\n",
        "            1.0 if self.legs[0].ground_contact else 0.0, # 6\n",
        "            1.0 if self.legs[1].ground_contact else 0.0, # 7\n",
        "        ]\n",
        "        assert len(state) == 8\n",
        "\n",
        "        # ----------------------------------------------------------------\n",
        "        # reward\n",
        "        reward = 0\n",
        "        shaping = (\n",
        "            # If the lander moves away from the landing pad, it loses reward\n",
        "            -100 * np.sqrt(state[0] * state[0] + state[1] * state[1]) # Euclidean distance\n",
        "            - 100 * np.sqrt(state[2] * state[2] + state[3] * state[3])\n",
        "\n",
        "            - 100 * abs(state[4])\n",
        "            # Each leg with ground contact is +10 points.\n",
        "            + 10 * state[6]\n",
        "            + 10 * state[7]\n",
        "        )  # And ten points for legs contact, the idea is if you\n",
        "        # lose contact again after landing, you get negative reward\n",
        "        if self.prev_shaping is not None:\n",
        "            reward = shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        # Firing the main engine is -0.3 points each frame. \n",
        "        reward -= (\n",
        "            m_power * 0.30\n",
        "        )  # less fuel spent is better, about -30 for heuristic landing\n",
        "        # Firing the side engine is -0.03 points each frame.\n",
        "        reward -= s_power * 0.03\n",
        "\n",
        "        done = False\n",
        "        if self.game_over or abs(state[0]) >= 1.0: # crashed?\n",
        "            done = True\n",
        "            reward = -100\n",
        "        if not self.lander.awake and (np.sqrt(state[0] * state[0] + state[1] * state[1]) == 0) and (np.sqrt(state[2] * state[2] + state[3] * state[3])==0): # rest\n",
        "            done = True\n",
        "            reward = +200\n",
        "        return np.array(state, dtype=np.float32), reward, done, {}\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  # def reset(self):\n",
        "  #     pass  # reward, done, info can't be included\n",
        "\n",
        "  # def render(self, mode='human'):\n",
        "  #     pass\n",
        "\n",
        "  # def close(self):\n",
        "  #     pass"
      ],
      "metadata": {
        "id": "0DW6wn84SBWf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### with wind and new reward (need to change to noisy observations)"
      ],
      "metadata": {
        "id": "095bT9dTPnAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_LunarLander_wind(LunarLander):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": FPS}\n",
        "    continuous = False\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        enable_wind: bool = False,\n",
        "        wind_power: float = 15.0,\n",
        "    ):\n",
        "        LunarLander.__init__(self)\n",
        "\n",
        "        self.enable_wind = enable_wind\n",
        "        self.wind_power = wind_power\n",
        "        self.wind_idx = np.random.randint(-9999, 9999)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "    def step(self, action):\n",
        "        if self.continuous:\n",
        "            action = np.clip(action, -1, +1).astype(np.float32)\n",
        "        else:\n",
        "            assert self.action_space.contains(action), \"%r (%s) invalid \" % (\n",
        "                action,\n",
        "                type(action),\n",
        "            )\n",
        "\n",
        "        # Engines\n",
        "        tip = (math.sin(self.lander.angle), math.cos(self.lander.angle))\n",
        "        side = (-tip[1], tip[0])\n",
        "        dispersion = [self.np_random.uniform(-1.0, +1.0) / SCALE for _ in range(2)]\n",
        "\n",
        "        m_power = 0.0\n",
        "\n",
        "\n",
        "        if self.enable_wind and not (\n",
        "            self.legs[0].ground_contact or self.legs[1].ground_contact\n",
        "        ):\n",
        "            # the function used for wind is tanh(sin(2 k x) + sin(pi k x)),\n",
        "            # which is proven to never be periodic, k = 0.01\n",
        "            wind_mag = (\n",
        "                math.tanh(\n",
        "                    math.sin(0.02 * self.wind_idx)\n",
        "                    + (math.sin(math.pi * 0.01 * self.wind_idx))\n",
        "                )\n",
        "                * self.wind_power\n",
        "            )\n",
        "            self.wind_idx += 1\n",
        "            print('calculated wind power:')\n",
        "            print(wind_mag)\n",
        "            self.lander.ApplyForceToCenter(\n",
        "                (wind_mag, 0.0),\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        if (self.continuous and action[0] > 0.0) or (\n",
        "            not self.continuous and action == 2\n",
        "        ):\n",
        "            # Main engine\n",
        "            if self.continuous:\n",
        "                m_power = (np.clip(action[0], 0.0, 1.0) + 1.0) * 0.5  # 0.5..1.0\n",
        "                assert m_power >= 0.5 and m_power <= 1.0\n",
        "            else:\n",
        "                m_power = 1.0\n",
        "            ox = (\n",
        "                tip[0] * (4 / SCALE + 2 * dispersion[0]) + side[0] * dispersion[1]\n",
        "            )  # 4 is move a bit downwards, +-2 for randomness\n",
        "            oy = -tip[1] * (4 / SCALE + 2 * dispersion[0]) - side[1] * dispersion[1]\n",
        "            impulse_pos = (self.lander.position[0] + ox, self.lander.position[1] + oy)\n",
        "            p = self._create_particle(\n",
        "                3.5,  # 3.5 is here to make particle speed adequate\n",
        "                impulse_pos[0],\n",
        "                impulse_pos[1],\n",
        "                m_power,\n",
        "            )  # particles are just a decoration\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * MAIN_ENGINE_POWER * m_power, oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * MAIN_ENGINE_POWER * m_power, -oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        s_power = 0.0\n",
        "        if (self.continuous and np.abs(action[1]) > 0.5) or (\n",
        "            not self.continuous and action in [1, 3]\n",
        "        ):\n",
        "            # Orientation engines\n",
        "            if self.continuous:\n",
        "                direction = np.sign(action[1])\n",
        "                s_power = np.clip(np.abs(action[1]), 0.5, 1.0)\n",
        "                assert s_power >= 0.5 and s_power <= 1.0\n",
        "            else:\n",
        "                direction = action - 2\n",
        "                s_power = 1.0\n",
        "            ox = tip[0] * dispersion[0] + side[0] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            oy = -tip[1] * dispersion[0] - side[1] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            impulse_pos = (\n",
        "                self.lander.position[0] + ox - tip[0] * 17 / SCALE,\n",
        "                self.lander.position[1] + oy + tip[1] * SIDE_ENGINE_HEIGHT / SCALE,\n",
        "            )\n",
        "            p = self._create_particle(0.7, impulse_pos[0], impulse_pos[1], s_power)\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * SIDE_ENGINE_POWER * s_power, oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * SIDE_ENGINE_POWER * s_power, -oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30)\n",
        "\n",
        "        pos = self.lander.position\n",
        "        vel = self.lander.linearVelocity\n",
        "        state = [\n",
        "            (pos.x - VIEWPORT_W / SCALE / 2) / (VIEWPORT_W / SCALE / 2), # 0: x position\n",
        "            (pos.y - (self.helipad_y + LEG_DOWN / SCALE)) / (VIEWPORT_H / SCALE / 2), # 1: y position\n",
        "            vel.x * (VIEWPORT_W / SCALE / 2) / FPS, # 2\n",
        "            vel.y * (VIEWPORT_H / SCALE / 2) / FPS, # 3\n",
        "            self.lander.angle, # 4\n",
        "            20.0 * self.lander.angularVelocity / FPS, # 5\n",
        "            1.0 if self.legs[0].ground_contact else 0.0, # 6\n",
        "            1.0 if self.legs[1].ground_contact else 0.0, # 7\n",
        "        ]\n",
        "        assert len(state) == 8\n",
        "\n",
        "        # ----------------------------------------------------------------\n",
        "        # reward\n",
        "        reward = 0\n",
        "        shaping = (\n",
        "            # If the lander moves away from the landing pad, it loses reward\n",
        "            -100 * np.sqrt(state[0] * state[0] + state[1] * state[1]) # Euclidean distance\n",
        "            - 100 * np.sqrt(state[2] * state[2] + state[3] * state[3])\n",
        "\n",
        "            - 100 * abs(state[4])\n",
        "            # Each leg with ground contact is +10 points.\n",
        "            + 10 * state[6]\n",
        "            + 10 * state[7]\n",
        "        )  # And ten points for legs contact, the idea is if you\n",
        "        # lose contact again after landing, you get negative reward\n",
        "        if self.prev_shaping is not None:\n",
        "            reward = shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        # Firing the main engine is -0.3 points each frame. \n",
        "        reward -= (\n",
        "            m_power * 0.30\n",
        "        )  # less fuel spent is better, about -30 for heuristic landing\n",
        "        # Firing the side engine is -0.03 points each frame.\n",
        "        reward -= s_power * 0.03\n",
        "\n",
        "        done = False\n",
        "        if self.game_over or abs(state[0]) >= 1.0: # crashed?\n",
        "            done = True\n",
        "            reward = -100\n",
        "        if not self.lander.awake and (np.sqrt(state[0] * state[0] + state[1] * state[1]) == 0) and (np.sqrt(state[2] * state[2] + state[3] * state[3])==0): # rest\n",
        "            done = True\n",
        "            reward = +200\n",
        "        return np.array(state, dtype=np.float32), reward, done, {}\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  # def reset(self):\n",
        "  #     pass  # reward, done, info can't be included\n",
        "\n",
        "  # def render(self, mode='human'):\n",
        "  #     pass\n",
        "\n",
        "  # def close(self):\n",
        "  #     pass"
      ],
      "metadata": {
        "id": "lUhMa-AOPrFG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### with obstacle and new reward"
      ],
      "metadata": {
        "id": "hU5fazVEArJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContactDetector(contactListener):\n",
        "    def __init__(self, env):\n",
        "        contactListener.__init__(self)\n",
        "        self.env = env\n",
        "\n",
        "    def BeginContact(self, contact):\n",
        "        if (\n",
        "                self.env.lander == contact.fixtureA.body\n",
        "                or self.env.lander == contact.fixtureB.body\n",
        "        ):\n",
        "            self.env.game_over = True\n",
        "        for i in range(2):\n",
        "            if self.env.legs[i] in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                self.env.legs[i].ground_contact = True\n",
        "\n",
        "    def EndContact(self, contact):\n",
        "        for i in range(2):\n",
        "            if self.env.legs[i] in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                self.env.legs[i].ground_contact = False\n",
        "\n",
        "class Custom_LunarLander_obs(LunarLander):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": FPS}\n",
        "    continuous = False\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        enable_wind: bool = False,\n",
        "        wind_power: float = 15.0,\n",
        "        obs_coords = [10, 10],\n",
        "        enable_obstacle: bool = True\n",
        "    ):\n",
        "        LunarLander.__init__(self)\n",
        "\n",
        "        self.enable_wind = enable_wind\n",
        "\n",
        "        self.obs_coords = obs_coords\n",
        "        self.enable_obstacle = enable_obstacle\n",
        "        self.wind_power = wind_power\n",
        "\n",
        "        self.wind_idx = np.random.randint(-9999, 9999)\n",
        "\n",
        "        # defining the polygon obstacle here:\n",
        "        vertices_poly = [(5, 5), (5, 2), (2, 2), (2, 5)]  # may need to change later\n",
        "        # self.obstacle = self.world.CreateStaticBody(\n",
        "        #\n",
        "        #     # shapes=polygonShape(centroid=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #     #                         self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #     #                    vertices= [(x / SCALE, y / SCALE) for x, y in vertices_poly]),\n",
        "        #     shapes=circleShape(pos=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #                             self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #                        radius=2),\n",
        "        #                         categoryBits=0x1000,\n",
        "        #\n",
        "        # )\n",
        "        self.obstacle = self.world.CreateStaticBody(\n",
        "            position=(self.obs_coords[0], self.obs_coords[1]),\n",
        "            # (self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "            # self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE))\n",
        "            angle=0.0,\n",
        "            fixtures=fixtureDef(\n",
        "                #circleShape(radius=2 / SCALE, pos=(0, 0)),\n",
        "                shape=circleShape(radius=20 / SCALE, \n",
        "                                  pos=(self.obs_coords[0],\n",
        "                                       self.obs_coords[1])),\n",
        "                # density=5.0,\n",
        "                # friction=0.1,\n",
        "                # categoryBits=0x0010,\n",
        "                # # maskBits=0x001,  # collide only with ground\n",
        "                # restitution=0.0,\n",
        "            ),  # 0.99 bouncy\n",
        "        )\n",
        "\n",
        "        self.obstacle.color1 = (0.5, 0.4, 0.9)\n",
        "        self.obstacle.color2 = (1, 1, 1)\n",
        "        # self.obstacle.alpha = 0.8  \n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            -np.inf, np.inf, shape=(10,), dtype=np.float32\n",
        "        )   \n",
        "\n",
        "    def reset(self):\n",
        "        self._destroy()\n",
        "        self.world.contactListener_keepref = ContactDetector(self)\n",
        "        self.world.contactListener = self.world.contactListener_keepref\n",
        "        self.game_over = False\n",
        "        self.prev_shaping = None\n",
        "\n",
        "        W = VIEWPORT_W / SCALE\n",
        "        H = VIEWPORT_H / SCALE\n",
        "\n",
        "        # terrain\n",
        "        CHUNKS = 11\n",
        "        height = self.np_random.uniform(0, H / 2, size=(CHUNKS + 1,))\n",
        "        chunk_x = [W / (CHUNKS - 1) * i for i in range(CHUNKS)]\n",
        "        self.helipad_x1 = chunk_x[CHUNKS // 2 - 1]\n",
        "        self.helipad_x2 = chunk_x[CHUNKS // 2 + 1]\n",
        "        self.helipad_y = H / 4\n",
        "        height[CHUNKS // 2 - 2] = self.helipad_y\n",
        "        height[CHUNKS // 2 - 1] = self.helipad_y\n",
        "        height[CHUNKS // 2 + 0] = self.helipad_y\n",
        "        height[CHUNKS // 2 + 1] = self.helipad_y\n",
        "        height[CHUNKS // 2 + 2] = self.helipad_y\n",
        "        smooth_y = [\n",
        "            0.33 * (height[i - 1] + height[i + 0] + height[i + 1])\n",
        "            for i in range(CHUNKS)\n",
        "        ]\n",
        "\n",
        "        self.moon = self.world.CreateStaticBody(\n",
        "            shapes=edgeShape(vertices=[(0, 0), (W, 0)])\n",
        "        )\n",
        "\n",
        "        # defining the polygon obstacle here----------------------------------\n",
        "        vertices_poly = [(5, 5), (5, 2), (2, 2), (2, 5)]  # may need to change later\n",
        "        # self.obstacle = self.world.CreateStaticBody(\n",
        "        #\n",
        "        #     # shapes=polygonShape(centroid=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #     #                         self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #     #                    vertices= [(x / SCALE, y / SCALE) for x, y in vertices_poly]),\n",
        "        #     shapes=circleShape(pos=(self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "        #                             self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE)),\n",
        "        #                        radius=2),\n",
        "        #                         categoryBits=0x1000,\n",
        "        #\n",
        "        # )\n",
        "        self.obstacle = self.world.CreateStaticBody(\n",
        "            position=(self.obs_coords[0], self.obs_coords[1]),\n",
        "            # (self.obs_coords[0] + VIEWPORT_W / 2 / SCALE,\n",
        "            # self.obs_coords[1] + (self.helipad_y + LEG_DOWN / SCALE))\n",
        "            angle=0.0,\n",
        "            fixtures=fixtureDef(\n",
        "                #circleShape(radius=2 / SCALE, pos=(0, 0)),\n",
        "                shape=circleShape(radius=20 / SCALE, \n",
        "                                  pos=(self.obs_coords[0],\n",
        "                                       self.obs_coords[1])),\n",
        "                # density=5.0,\n",
        "                # friction=0.1,\n",
        "                # categoryBits=0x0010,\n",
        "                # # maskBits=0x001,  # collide only with ground\n",
        "                # restitution=0.0,\n",
        "            ),  # 0.99 bouncy\n",
        "        )\n",
        "\n",
        "        self.obstacle.color1 = (0.5, 0.4, 0.9)\n",
        "        self.obstacle.color2 = (1, 1, 1)\n",
        "        # self.obstacle.alpha = 0.8\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "        self.sky_polys = []\n",
        "        for i in range(CHUNKS - 1):\n",
        "            p1 = (chunk_x[i], smooth_y[i])\n",
        "            p2 = (chunk_x[i + 1], smooth_y[i + 1])\n",
        "            self.moon.CreateEdgeFixture(vertices=[p1, p2], density=0, friction=0.1)\n",
        "            self.sky_polys.append([p1, p2, (p2[0], H), (p1[0], H)])\n",
        "\n",
        "        self.moon.color1 = (0.0, 0.0, 0.0)\n",
        "        self.moon.color2 = (0.0, 0.0, 0.0)\n",
        "\n",
        "        initial_y = VIEWPORT_H / SCALE\n",
        "        self.lander = self.world.CreateDynamicBody(\n",
        "            position=(VIEWPORT_W / SCALE / 2, initial_y),\n",
        "            angle=0.0,\n",
        "            fixtures=fixtureDef(\n",
        "                shape=polygonShape(\n",
        "                    vertices=[(x / SCALE, y / SCALE) for x, y in LANDER_POLY]\n",
        "                ),\n",
        "                density=5.0,\n",
        "                friction=0.1,\n",
        "                categoryBits=0x0010,\n",
        "                maskBits=0x001,  # collide only with ground\n",
        "                restitution=0.0,\n",
        "            ),  # 0.99 bouncy\n",
        "        )\n",
        "        self.lander.color1 = (0.5, 0.4, 0.9)\n",
        "        self.lander.color2 = (0.3, 0.3, 0.5)\n",
        "        self.lander.ApplyForceToCenter(\n",
        "            (\n",
        "                self.np_random.uniform(-INITIAL_RANDOM, INITIAL_RANDOM),\n",
        "                self.np_random.uniform(-INITIAL_RANDOM, INITIAL_RANDOM),\n",
        "            ),\n",
        "            True,\n",
        "        )\n",
        "\n",
        "        self.legs = []\n",
        "        for i in [-1, +1]:\n",
        "            leg = self.world.CreateDynamicBody(\n",
        "                position=(VIEWPORT_W / SCALE / 2 - i * LEG_AWAY / SCALE, initial_y),\n",
        "                angle=(i * 0.05),\n",
        "                fixtures=fixtureDef(\n",
        "                    shape=polygonShape(box=(LEG_W / SCALE, LEG_H / SCALE)),\n",
        "                    density=1.0,\n",
        "                    restitution=0.0,\n",
        "                    categoryBits=0x0020,\n",
        "                    maskBits=0x001,\n",
        "                ),\n",
        "            )\n",
        "            leg.ground_contact = False\n",
        "            leg.color1 = (0.5, 0.4, 0.9)\n",
        "            leg.color2 = (0.3, 0.3, 0.5)\n",
        "            rjd = revoluteJointDef(\n",
        "                bodyA=self.lander,\n",
        "                bodyB=leg,\n",
        "                localAnchorA=(0, 0),\n",
        "                localAnchorB=(i * LEG_AWAY / SCALE, LEG_DOWN / SCALE),\n",
        "                enableMotor=True,\n",
        "                enableLimit=True,\n",
        "                maxMotorTorque=LEG_SPRING_TORQUE,\n",
        "                motorSpeed=+0.3 * i,  # low enough not to jump back into the sky\n",
        "            )\n",
        "            if i == -1:\n",
        "                rjd.lowerAngle = (\n",
        "                        +0.9 - 0.5\n",
        "                )  # The most esoteric numbers here, angled legs have freedom to travel within\n",
        "                rjd.upperAngle = +0.9\n",
        "            else:\n",
        "                rjd.lowerAngle = -0.9\n",
        "                rjd.upperAngle = -0.9 + 0.5\n",
        "            leg.joint = self.world.CreateJoint(rjd)\n",
        "            self.legs.append(leg)\n",
        "\n",
        "        self.drawlist = [self.lander] + self.legs\n",
        "        \n",
        "\n",
        "        return self.step(np.array([0, 0]) if self.continuous else 0)[0]\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.continuous:\n",
        "            action = np.clip(action, -1, +1).astype(np.float32)\n",
        "        else:\n",
        "            assert self.action_space.contains(action), \"%r (%s) invalid \" % (\n",
        "                action,\n",
        "                type(action),\n",
        "            )\n",
        "\n",
        "        # Engines\n",
        "        tip = (math.sin(self.lander.angle), math.cos(self.lander.angle))\n",
        "        side = (-tip[1], tip[0])\n",
        "        dispersion = [self.np_random.uniform(-1.0, +1.0) / SCALE for _ in range(2)]\n",
        "\n",
        "        m_power = 0.0\n",
        "        if (self.continuous and action[0] > 0.0) or (\n",
        "            not self.continuous and action == 2\n",
        "        ):\n",
        "            # Main engine\n",
        "            if self.continuous:\n",
        "                m_power = (np.clip(action[0], 0.0, 1.0) + 1.0) * 0.5  # 0.5..1.0\n",
        "                assert m_power >= 0.5 and m_power <= 1.0\n",
        "            else:\n",
        "                m_power = 1.0\n",
        "            ox = (\n",
        "                tip[0] * (4 / SCALE + 2 * dispersion[0]) + side[0] * dispersion[1]\n",
        "            )  # 4 is move a bit downwards, +-2 for randomness\n",
        "            oy = -tip[1] * (4 / SCALE + 2 * dispersion[0]) - side[1] * dispersion[1]\n",
        "            impulse_pos = (self.lander.position[0] + ox, self.lander.position[1] + oy)\n",
        "            p = self._create_particle(\n",
        "                3.5,  # 3.5 is here to make particle speed adequate\n",
        "                impulse_pos[0],\n",
        "                impulse_pos[1],\n",
        "                m_power,\n",
        "            )  # particles are just a decoration\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * MAIN_ENGINE_POWER * m_power, oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * MAIN_ENGINE_POWER * m_power, -oy * MAIN_ENGINE_POWER * m_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        s_power = 0.0\n",
        "        if (self.continuous and np.abs(action[1]) > 0.5) or (\n",
        "            not self.continuous and action in [1, 3]\n",
        "        ):\n",
        "            # Orientation engines\n",
        "            if self.continuous:\n",
        "                direction = np.sign(action[1])\n",
        "                s_power = np.clip(np.abs(action[1]), 0.5, 1.0)\n",
        "                assert s_power >= 0.5 and s_power <= 1.0\n",
        "            else:\n",
        "                direction = action - 2\n",
        "                s_power = 1.0\n",
        "            ox = tip[0] * dispersion[0] + side[0] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            oy = -tip[1] * dispersion[0] - side[1] * (\n",
        "                3 * dispersion[1] + direction * SIDE_ENGINE_AWAY / SCALE\n",
        "            )\n",
        "            impulse_pos = (\n",
        "                self.lander.position[0] + ox - tip[0] * 17 / SCALE,\n",
        "                self.lander.position[1] + oy + tip[1] * SIDE_ENGINE_HEIGHT / SCALE,\n",
        "            )\n",
        "            p = self._create_particle(0.7, impulse_pos[0], impulse_pos[1], s_power)\n",
        "            p.ApplyLinearImpulse(\n",
        "                (ox * SIDE_ENGINE_POWER * s_power, oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "            self.lander.ApplyLinearImpulse(\n",
        "                (-ox * SIDE_ENGINE_POWER * s_power, -oy * SIDE_ENGINE_POWER * s_power),\n",
        "                impulse_pos,\n",
        "                True,\n",
        "            )\n",
        "\n",
        "        self.world.Step(1.0 / FPS, 6 * 30, 2 * 30)\n",
        "\n",
        "        pos = self.lander.position\n",
        "        # print([pos.x,pos.y])\n",
        "        vel = self.lander.linearVelocity\n",
        "        # print([vel.x,vel.y])\n",
        "        state = [\n",
        "            (pos.x - VIEWPORT_W / SCALE / 2) / (VIEWPORT_W / SCALE / 2), # 0: x position\n",
        "            (pos.y - (self.helipad_y + LEG_DOWN / SCALE)) / (VIEWPORT_H / SCALE / 2), # 1: y position\n",
        "            vel.x * (VIEWPORT_W / SCALE / 2) / FPS, # 2\n",
        "            vel.y * (VIEWPORT_H / SCALE / 2) / FPS, # 3\n",
        "            self.lander.angle, # 4\n",
        "            20.0 * self.lander.angularVelocity / FPS, # 5\n",
        "            1.0 if self.legs[0].ground_contact else 0.0, # 6\n",
        "            1.0 if self.legs[1].ground_contact else 0.0, # 7\n",
        "\n",
        "            (pos.x - self.obs_coords[0] / SCALE) / (VIEWPORT_W / SCALE / 2), # 8: x position\n",
        "            (pos.y - self.obs_coords[1] / SCALE) / (VIEWPORT_H / SCALE / 2), # 9: y position\n",
        "\n",
        "        ]\n",
        "        assert len(state) == 10\n",
        "\n",
        "        # ----------------------------------------------------------------\n",
        "        # reward\n",
        "        # distance_to_obstacle = np.sqrt((pos.x - (self.obs_coords[0] +\n",
        "        #                                     VIEWPORT_W / SCALE / 2)) ** 2 +\n",
        "        #                         (pos.y - (self.obs_coords[1] +\n",
        "\n",
        "        #                                   (self.helipad_y + LEG_DOWN / SCALE))) ** 2)\n",
        "        distance_to_obstacle = np.sqrt(state[8] * state[8] + state[9] * state[9])\n",
        "        # print((distance_to_obstacle <= (20 / SCALE)))\n",
        "        # if (distance_to_obstacle <= (1)):\n",
        "        #     print('dangerously close to obstacle!')\n",
        "\n",
        "        reward = 0\n",
        "        shaping = (\n",
        "            # If the lander moves away from the landing pad, it loses reward\n",
        "            - 150 * np.sqrt(state[0] * state[0] + state[1] * state[1]) # Euclidean distance\n",
        "            - 50 * np.sqrt(state[2] * state[2] + state[3] * state[3])\n",
        "\n",
        "            - 100 * abs(state[4])\n",
        "            # Each leg with ground contact is +10 points.\n",
        "            + 10 * state[6]\n",
        "            + 10 * state[7]\n",
        "            - 50 * (distance_to_obstacle <= (20 / SCALE)) # obstacles \n",
        "        )  # And ten points for legs contact, the idea is if you\n",
        "        # lose contact again after landing, you get negative reward\n",
        "        if self.prev_shaping is not None:\n",
        "            reward = shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        # Firing the main engine is -0.3 points each frame. \n",
        "        reward -= (\n",
        "            m_power * 0.30\n",
        "        )  # less fuel spent is better, about -30 for heuristic landing\n",
        "        # Firing the side engine is -0.03 points each frame.\n",
        "        reward -= s_power * 0.03\n",
        "\n",
        "        done = False\n",
        "        if self.game_over or abs(state[0]) >= 1.0: # crashed?\n",
        "            done = True\n",
        "            reward = -100\n",
        "        if not self.lander.awake and (np.sqrt(state[0] * state[0] + state[1] * state[1]) == 0) and (np.sqrt(state[2] * state[2] + state[3] * state[3])==0): # rest\n",
        "            done = True\n",
        "            reward = +200\n",
        "\n",
        "        return np.array(state, dtype=np.float32), reward, done, {}\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        from gym.envs.classic_control import rendering\n",
        "\n",
        "        if self.viewer is None:\n",
        "            self.viewer = rendering.Viewer(VIEWPORT_W, VIEWPORT_H)\n",
        "            self.viewer.set_bounds(0, VIEWPORT_W / SCALE, 0, VIEWPORT_H / SCALE)\n",
        "\n",
        "        for obj in self.particles:\n",
        "            obj.ttl -= 0.15\n",
        "            obj.color1 = (\n",
        "                max(0.2, 0.2 + obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "            )\n",
        "            obj.color2 = (\n",
        "                max(0.2, 0.2 + obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "                max(0.2, 0.5 * obj.ttl),\n",
        "            )\n",
        "\n",
        "        self._clean_particles(False)\n",
        "        # print('drawlist')\n",
        "        # print(self.drawlist)\n",
        "        for p in self.sky_polys:\n",
        "            self.viewer.draw_polygon(p, color=(0, 0, 0))\n",
        "        # editing below line to draw obstacle\n",
        "        for obj in self.particles + self.drawlist:\n",
        "            for f in obj.fixtures:\n",
        "                trans = f.body.transform\n",
        "                if type(f.shape) is circleShape:\n",
        "                    t = rendering.Transform(translation=trans * f.shape.pos)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj.color1, filled=True\n",
        "                    ).add_attr(t)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj.color2, filled=False, linewidth=2\n",
        "                    ).add_attr(t)\n",
        "                    # t = rendering.Transform((100, 100))  # Position\n",
        "                    # self.viewer.draw_circle(20).add_attr(t)  # Add transform for position\n",
        "                    # self.viewer.render()\n",
        "                else:\n",
        "                    path = [trans * v for v in f.shape.vertices]\n",
        "                    # print('poly shape in object fixtures')\n",
        "                    # print(f)\n",
        "                    self.viewer.draw_polygon(path, color=obj.color1)\n",
        "                    path.append(path[0])\n",
        "                    self.viewer.draw_polyline(path, color=obj.color2, linewidth=2)\n",
        "\n",
        "        for obj2 in [self.obstacle]:\n",
        "            # print('rendering obstacle')\n",
        "            # print(obj2)\n",
        "            for f in obj2.fixtures:\n",
        "                trans = f.body.transform\n",
        "                if type(f.shape) is circleShape:\n",
        "                    # print('printing circle of radius')\n",
        "                    #t = rendering.Transform(translation=trans * f.shape.pos)\n",
        "                    t = rendering.Transform((self.obs_coords[0], self.obs_coords[1]))\n",
        "                    # print(f.shape.radius)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj2.color1, filled=True\n",
        "                    ).add_attr(t)\n",
        "                    self.viewer.draw_circle(\n",
        "                        f.shape.radius, 20, color=obj2.color2, filled=False, linewidth=2\n",
        "                    ).add_attr(t)\n",
        "                    # t = rendering.Transform((10, 10))  # Position\n",
        "                    # self.viewer.draw_circle(2).add_attr(t)  # Add transform for position\n",
        "                    # self.viewer.render()\n",
        "                else:\n",
        "                    path = [trans * v for v in f.shape.vertices]\n",
        "                    # print('poly shape in object fixtures')\n",
        "                    # print(f)\n",
        "                    self.viewer.draw_polygon(path, color=obj2.color1)\n",
        "                    path.append(path[0])\n",
        "                    self.viewer.draw_polyline(path, color=obj2.color2, linewidth=2)\n",
        "\n",
        "        for x in [self.helipad_x1, self.helipad_x2]:\n",
        "            flagy1 = self.helipad_y\n",
        "            flagy2 = flagy1 + 50 / SCALE\n",
        "            self.viewer.draw_polyline([(x, flagy1), (x, flagy2)], color=(1, 1, 1))\n",
        "            self.viewer.draw_polygon(\n",
        "                [\n",
        "                    (x, flagy2),\n",
        "                    (x, flagy2 - 10 / SCALE),\n",
        "                    (x + 25 / SCALE, flagy2 - 5 / SCALE),\n",
        "                ],\n",
        "                color=(0.8, 0.8, 0),\n",
        "            )\n",
        "\n",
        "        return self.viewer.render(return_rgb_array=mode == \"rgb_array\")\n",
        "\n",
        "\n",
        "    \n",
        "  # def reset(self):\n",
        "  #     pass  # reward, done, info can't be included\n",
        "\n",
        "  # def render(self, mode='human'):\n",
        "  #     pass\n",
        "\n",
        "  # def close(self):\n",
        "  #     pass"
      ],
      "metadata": {
        "id": "7Nxu5rsZ4MH1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### register environment"
      ],
      "metadata": {
        "id": "DzZ83S3UzBYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### register baseline anv"
      ],
      "metadata": {
        "id": "8SD7DX6hoX7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_env = Custom_LunarLander_reward()\n",
        "new_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3abf00-4c9a-4836-d5fe-ab39b9b035b6",
        "id": "mAGafux6oX7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Custom_LunarLander_wind at 0x7fbe3b8c9f50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "check_env(new_env)"
      ],
      "metadata": {
        "id": "PkBL7IZQoX7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.envs.registration import register\n",
        "# Example for the CartPole environment\n",
        "register(\n",
        "    # unique identifier for the env `name-version`\n",
        "    id=\"LunarLander-v3\",\n",
        "    # path to the class for creating the env\n",
        "    # Note: entry_point also accept a class as input (and not only a string)\n",
        "    entry_point= Custom_LunarLander_reward,\n",
        "    # Max number of steps per episode, using a `TimeLimitWrapper`\n",
        "    max_episode_steps=1500,\n",
        ")"
      ],
      "metadata": {
        "id": "WvFoF2FdoX7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### register wind anv"
      ],
      "metadata": {
        "id": "cxqVS339oKRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_env = Custom_LunarLander_wind()\n",
        "new_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3abf00-4c9a-4836-d5fe-ab39b9b035b6",
        "id": "phZM2GOCSZcT"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Custom_LunarLander_wind at 0x7fbe3b8c9f50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_env(new_env)"
      ],
      "metadata": {
        "id": "panzssD8SZcU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.envs.registration import register\n",
        "# Example for the CartPole environment\n",
        "register(\n",
        "    # unique identifier for the env `name-version`\n",
        "    id=\"LunarLander_wind-v1\",\n",
        "    # path to the class for creating the env\n",
        "    # Note: entry_point also accept a class as input (and not only a string)\n",
        "    entry_point= Custom_LunarLander_wind,\n",
        "    # Max number of steps per episode, using a `TimeLimitWrapper`\n",
        "    max_episode_steps=1500,\n",
        ")"
      ],
      "metadata": {
        "id": "rtz9Xc6QSZcU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### register obstacle anv"
      ],
      "metadata": {
        "id": "YJkdBNEHiLle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "check environment"
      ],
      "metadata": {
        "id": "xGf0_9im0Y3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_env = Custom_LunarLander_obs()\n",
        "new_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "GdKLT2SiGCiV",
        "outputId": "1a84d175-dfd9-4685-eab9-2fa5e5ef797f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-63c2b47b5adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustom_LunarLander_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Custom_LunarLander_obs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_env(new_env)"
      ],
      "metadata": {
        "id": "kG6IM6zW2IPm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.envs.registration import register\n",
        "# Example for the CartPole environment\n",
        "register(\n",
        "    # unique identifier for the env `name-version`\n",
        "    id=\"LunarLander_obs-v1\",\n",
        "    # path to the class for creating the env\n",
        "    # Note: entry_point also accept a class as input (and not only a string)\n",
        "    entry_point= Custom_LunarLander_obs,\n",
        "    # Max number of steps per episode, using a `TimeLimitWrapper`\n",
        "    max_episode_steps=1500,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "C1cIXPTaJsQG",
        "outputId": "0b427a16-9648-4ea3-fa8b-a49860a25ec8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-118a5885058b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# path to the class for creating the env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Note: entry_point also accept a class as input (and not only a string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mentry_point\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mCustom_LunarLander_obs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Max number of steps per episode, using a `TimeLimitWrapper`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Custom_LunarLander_obs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### define model in new env"
      ],
      "metadata": {
        "id": "KdG01o1IzxGG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "kMkD1Ku8zq9q"
      },
      "source": [
        "Now, let us setup our model and the DQN algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {},
        "id": "hun_d8rYzq9p"
      },
      "outputs": [],
      "source": [
        "nn_layers = [64,64] #This is the configuration of your neural network. Currently, we have two layers, each consisting of 64 neurons.\n",
        "                    #If you want three layers with 64 neurons each, set the value to [64,64,64] and so on.\n",
        "\n",
        "learning_rate = 0.001 #This is the step-size with which the gradient descent is carried out.\n",
        "                      #Tip: Use smaller step-sizes for larger networks.\n",
        "\n",
        "log_dir = \"/tmp/gym/\"\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model for baseline env"
      ],
      "metadata": {
        "id": "0EfzaHwhoxTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "5J0MmqyPzq9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "66e5baed-35fc-40ed-8f92-2d8cb8c6e0b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-aea702badd6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLander-v3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#You can also load other environments like cartpole, MountainCar, Acrobot. Refer to https://gym.openai.com/docs/ for descriptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#For example, if you would like to load Cartpole, just replace the above statement with \"env = gym.make('CartPole-v1')\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
          ]
        }
      ],
      "source": [
        "# Create environment\n",
        "env = gym.make('LunarLander-v3')\n",
        "#You can also load other environments like cartpole, MountainCar, Acrobot. Refer to https://gym.openai.com/docs/ for descriptions.\n",
        "#For example, if you would like to load Cartpole, just replace the above statement with \"env = gym.make('CartPole-v1')\".\n",
        "\n",
        "env = stable_baselines3.common.monitor.Monitor(env, log_dir )\n",
        "\n",
        "callback = EvalCallback(env,log_path = log_dir, deterministic=True) #For evaluating the performance of the agent periodically and logging the results.\n",
        "\n",
        "policy_kwargs = dict(activation_fn=torch.nn.ReLU,\n",
        "                     net_arch=nn_layers)\n",
        "model1 = DQN(\"MlpPolicy\", env, policy_kwargs = policy_kwargs,\n",
        "            learning_rate=learning_rate,\n",
        "            batch_size=1,  #for simplicity, we are not doing batch update.\n",
        "            buffer_size=1, #size of experience of replay buffer. Set to 1 as batch update is not done\n",
        "            learning_starts=1, #learning starts immediately!\n",
        "            gamma=0.99, #discount facto. range is between 0 and 1.\n",
        "            tau = 1,  #the soft update coefficient for updating the target network\n",
        "            target_update_interval=1, #update the target network immediately.\n",
        "            train_freq=(1,\"step\"), #train the network at every step.\n",
        "            max_grad_norm = 10, #the maximum value for the gradient clipping\n",
        "            exploration_initial_eps = 1, #initial value of random action probability\n",
        "            exploration_fraction = 0.5, #fraction of entire training period over which the exploration rate is reduced\n",
        "            gradient_steps = 1, #number of gradient steps\n",
        "            seed = 1, #seed for the pseudo random generators\n",
        "            verbose=0) #Set verbose to 1 to observe training logs. We encourage you to set the verbose to 1.\n",
        "\n",
        "# You can also experiment with other RL algorithms like A2C, PPO, DDPG etc. Refer to  https://stable-baselines3.readthedocs.io/en/master/guide/examples.html\n",
        "#for documentation. For example, if you would like to run DDPG, just replace \"DQN\" above with \"DDPG\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model for wind env"
      ],
      "metadata": {
        "id": "5X5pRAdLpf30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment\n",
        "env = gym.make('LunarLander_wind-v1')\n",
        "#You can also load other environments like cartpole, MountainCar, Acrobot. Refer to https://gym.openai.com/docs/ for descriptions.\n",
        "#For example, if you would like to load Cartpole, just replace the above statement with \"env = gym.make('CartPole-v1')\".\n",
        "\n",
        "env = stable_baselines3.common.monitor.Monitor(env, log_dir )\n",
        "\n",
        "callback = EvalCallback(env,log_path = log_dir, deterministic=True) #For evaluating the performance of the agent periodically and logging the results.\n",
        "\n",
        "policy_kwargs = dict(activation_fn=torch.nn.ReLU,\n",
        "                     net_arch=nn_layers)\n",
        "model2 = DQN(\"MlpPolicy\", env, policy_kwargs = policy_kwargs,\n",
        "            learning_rate=learning_rate,\n",
        "            batch_size=1,  #for simplicity, we are not doing batch update.\n",
        "            buffer_size=1, #size of experience of replay buffer. Set to 1 as batch update is not done\n",
        "            learning_starts=1, #learning starts immediately!\n",
        "            gamma=0.99, #discount facto. range is between 0 and 1.\n",
        "            tau = 1,  #the soft update coefficient for updating the target network\n",
        "            target_update_interval=1, #update the target network immediately.\n",
        "            train_freq=(1,\"step\"), #train the network at every step.\n",
        "            max_grad_norm = 10, #the maximum value for the gradient clipping\n",
        "            exploration_initial_eps = 1, #initial value of random action probability\n",
        "            exploration_fraction = 0.5, #fraction of entire training period over which the exploration rate is reduced\n",
        "            gradient_steps = 1, #number of gradient steps\n",
        "            seed = 1, #seed for the pseudo random generators\n",
        "            verbose=0) #Set verbose to 1 to observe training logs. We encourage you to set the verbose to 1.\n",
        "\n",
        "# You can also experiment with other RL algorithms like A2C, PPO, DDPG etc. Refer to  https://stable-baselines3.readthedocs.io/en/master/guide/examples.html\n",
        "#for documentation. For example, if you would like to run DDPG, just replace \"DQN\" above with \"DDPG\"."
      ],
      "metadata": {
        "id": "KKH6z9vWo-rX",
        "outputId": "8e7bb415-ffdf-4b21-b4c3-ad6753d44b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f2bab3abe768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLander_wind-v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#You can also load other environments like cartpole, MountainCar, Acrobot. Refer to https://gym.openai.com/docs/ for descriptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#For example, if you would like to load Cartpole, just replace the above statement with \"env = gym.make('CartPole-v1')\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model for obstacle env"
      ],
      "metadata": {
        "id": "rkJifcG-pibo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment\n",
        "env = gym.make('LunarLander_obs-v1')\n",
        "#You can also load other environments like cartpole, MountainCar, Acrobot. Refer to https://gym.openai.com/docs/ for descriptions.\n",
        "#For example, if you would like to load Cartpole, just replace the above statement with \"env = gym.make('CartPole-v1')\".\n",
        "\n",
        "env = stable_baselines3.common.monitor.Monitor(env, log_dir )\n",
        "\n",
        "callback = EvalCallback(env,log_path = log_dir, deterministic=True) #For evaluating the performance of the agent periodically and logging the results.\n",
        "\n",
        "policy_kwargs = dict(activation_fn=torch.nn.ReLU,\n",
        "                     net_arch=nn_layers)\n",
        "model3 = DQN(\"MlpPolicy\", env, policy_kwargs = policy_kwargs,\n",
        "            learning_rate=learning_rate,\n",
        "            batch_size=1,  #for simplicity, we are not doing batch update.\n",
        "            buffer_size=1, #size of experience of replay buffer. Set to 1 as batch update is not done\n",
        "            learning_starts=1, #learning starts immediately!\n",
        "            gamma=0.99, #discount facto. range is between 0 and 1.\n",
        "            tau = 1,  #the soft update coefficient for updating the target network\n",
        "            target_update_interval=1, #update the target network immediately.\n",
        "            train_freq=(1,\"step\"), #train the network at every step.\n",
        "            max_grad_norm = 10, #the maximum value for the gradient clipping\n",
        "            exploration_initial_eps = 1, #initial value of random action probability\n",
        "            exploration_fraction = 0.5, #fraction of entire training period over which the exploration rate is reduced\n",
        "            gradient_steps = 1, #number of gradient steps\n",
        "            seed = 1, #seed for the pseudo random generators\n",
        "            verbose=0) #Set verbose to 1 to observe training logs. We encourage you to set the verbose to 1.\n",
        "\n",
        "# You can also experiment with other RL algorithms like A2C, PPO, DDPG etc. Refer to  https://stable-baselines3.readthedocs.io/en/master/guide/examples.html\n",
        "#for documentation. For example, if you would like to run DDPG, just replace \"DQN\" above with \"DDPG\"."
      ],
      "metadata": {
        "id": "-qmgq4cYo_vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### visualize new environment"
      ],
      "metadata": {
        "id": "aFsU1I3KzLEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### baseline env"
      ],
      "metadata": {
        "id": "CbQkquvOq2-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_env = wrap_env(gym.make(\"LunarLander-v3\"))\n",
        "observation = new_env.reset()\n",
        "total_reward = 0\n",
        "\n",
        "while True:\n",
        "  new_env.render()\n",
        "  action, states = model1.predict(observation, deterministic=True)\n",
        "  observation, reward, done, info = new_env.step(action)\n",
        "  total_reward += reward\n",
        "  if done:\n",
        "    break;\n",
        "\n",
        "# print(total_reward)\n",
        "new_env.close()\n",
        "show_video()"
      ],
      "metadata": {
        "id": "HeHfAR-g4ttm",
        "outputId": "3d667507-ef60-4d9b-d619-903cf7157c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video alt=\"test\" autoplay\n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### wind env"
      ],
      "metadata": {
        "id": "R-ajkamirAHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_env = wrap_env(gym.make(\"LunarLander_wind-v1\"))\n",
        "observation = new_env.reset()\n",
        "total_reward = 0\n",
        "\n",
        "while True:\n",
        "  new_env.render()\n",
        "  action, states = model2.predict(observation, deterministic=True)\n",
        "  observation, reward, done, info = new_env.step(action)\n",
        "  total_reward += reward\n",
        "  if done:\n",
        "    break;\n",
        "\n",
        "# print(total_reward)\n",
        "new_env.close()\n",
        "show_video()"
      ],
      "metadata": {
        "id": "ZrLTg_XhqvmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### obs env"
      ],
      "metadata": {
        "id": "TTn86crSrGWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_env = wrap_env(gym.make(\"LunarLander_obs-v1\"))\n",
        "observation = new_env.reset()\n",
        "total_reward = 0\n",
        "\n",
        "while True:\n",
        "  new_env.render()\n",
        "  action, states = model3.predict(observation, deterministic=True)\n",
        "  observation, reward, done, info = new_env.step(action)\n",
        "  total_reward += reward\n",
        "  if done:\n",
        "    break;\n",
        "\n",
        "# print(total_reward)\n",
        "new_env.close()\n",
        "show_video()"
      ],
      "metadata": {
        "id": "iEsMeJy-rFWy",
        "outputId": "9817e7a7-11dd-4ea7-afac-f150b1e3e554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-27de67e64f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LunarLander_obs-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'wrap_env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train the model and visualize"
      ],
      "metadata": {
        "id": "zKB-D-Cy4e7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### baseline"
      ],
      "metadata": {
        "id": "2UMzz-ONrglK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {},
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b9773b-beea-477d-cfa7-be742f7ba400",
        "id": "FV4kq74Ozq9q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=10000, episode_reward=-785.10 +/- 381.23\n",
            "Episode length: 104.80 +/- 37.28\n",
            "New best mean reward!\n",
            "Eval num_timesteps=20000, episode_reward=-633.22 +/- 81.71\n",
            "Episode length: 114.20 +/- 29.68\n",
            "New best mean reward!\n",
            "Eval num_timesteps=30000, episode_reward=14.19 +/- 32.40\n",
            "Episode length: 79.00 +/- 9.14\n",
            "New best mean reward!\n",
            "Eval num_timesteps=40000, episode_reward=-330.72 +/- 51.03\n",
            "Episode length: 240.20 +/- 145.50\n",
            "Eval num_timesteps=50000, episode_reward=-17.39 +/- 147.17\n",
            "Episode length: 829.20 +/- 563.86\n",
            "Eval num_timesteps=60000, episode_reward=59.51 +/- 32.05\n",
            "Episode length: 382.80 +/- 558.66\n",
            "New best mean reward!\n",
            "Eval num_timesteps=70000, episode_reward=133.76 +/- 72.74\n",
            "Episode length: 1222.60 +/- 554.80\n",
            "New best mean reward!\n",
            "Eval num_timesteps=80000, episode_reward=40.79 +/- 21.69\n",
            "Episode length: 92.80 +/- 20.45\n",
            "Eval num_timesteps=90000, episode_reward=101.25 +/- 74.38\n",
            "Episode length: 975.00 +/- 646.38\n",
            "Eval num_timesteps=100000, episode_reward=67.41 +/- 69.90\n",
            "Episode length: 410.00 +/- 546.42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7f3f646f8390>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model1.learn(total_timesteps=100000, log_interval=10, callback=callback, eval_log_path=log_dir)\n",
        "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
        "# view the performance at every training episode.\n",
        "# how to read monitor.csv: ep_info = {\"r\": round(ep_rew, 6), \"l\": ep_len, \"t\": round(time.time() - self.t_start, 6)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {},
        "outputId": "e30c1096-e870-409e-93fd-de3a790e8332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "_B6I243kzq9q"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video alt=\"test\" autoplay\n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = wrap_env(gym.make(\"LunarLander-v4\"))\n",
        "observation = env.reset()\n",
        "while True:\n",
        "  env.render()\n",
        "  action, _states = model.predict(observation, deterministic=True)\n",
        "  observation, reward, done, info = env.step(action)\n",
        "  if done:\n",
        "    break;\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {},
        "outputId": "9e40479c-3613-47e8-eb5f-9855139292bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "voWFVkMGzq9r"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Episode Rewards')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x, y = ts2xy(load_results(log_dir), 'timesteps')  # Organising the logged results in to a clean format for plotting. timesteps episodes\n",
        "plt.plot(x,y)\n",
        "plt.ylim([-300, 300])\n",
        "plt.xlabel('Timesteps')\n",
        "plt.ylabel('Episode Rewards')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ptpdnpwGobbz"
      },
      "source": [
        "---\n",
        "# References\n",
        "\n",
        "1. Stable Baselines Framework: https://stable-baselines3.readthedocs.io/en/master/guide/examples.html\n",
        "\n",
        "2. Lunar Lander Environment: https://gym.openai.com/envs/LunarLander-v2/\n",
        "\n",
        "3. OpenAI gym environments: https://gym.openai.com/docs/\n",
        "\n",
        "4. A good reference for introduction to RL: http://incompleteideas.net/book/the-book-2nd.html\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lunar_lander_group1_atcheke",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}